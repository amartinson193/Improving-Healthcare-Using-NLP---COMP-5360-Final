{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-romance",
   "metadata": {},
   "source": [
    "# Changes from v13\n",
    "* Splitting out the data by CPT section and running one model for each one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-basis",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## Questions\n",
    "* Run the data for each category with only no filter, one, and three CPT codes for each discharge summary\n",
    "    * ANSWER: It performs better with only 1 CPT per note and 3 had a decrease of 3% in accuracy\n",
    "* Does including all notes/CPT sections improve accuracy?\n",
    "    * ANSWER: No, it decreased the accuracy\n",
    "* Does including some sections improve accuracy when included with discharge summary?\n",
    "    * No, accuracy went from 80% to 71%- at least for the E/M category\n",
    "* Does accuracy improve when there are more notes per CPT code?\n",
    "    * Yes\n",
    "* What is the lowest threshold I can use without decreasing accuracy?\n",
    "    * It seems like I don't need a threshold\n",
    "* Does imbalance correction improve model accuracy?\n",
    "    * Yes, it makes a huge difference\n",
    "* Is undersampling or over-sampling a better method for imbalance correction?\n",
    "    * Oversampling since the lowest records only contain one note - could also try SMOTE and see if that gives better results or not\n",
    "* Use label encoder for the CPT codes\n",
    "    * Does the accuracy improve when using labelencoder?\n",
    "* Is limiting CPT codes to just one excluding CPT codes?\n",
    "    * No\n",
    "* Can I use the descriptions in the CPT table to help improve my analysis?\n",
    "    * Yes, only for 94002 and 94003\n",
    "* What is the accuracy when filtered to each CPT section individually?\n",
    "\n",
    "# Next Steps\n",
    "\n",
    "* Adjust model so it can be run in smaller chunks\n",
    "* Check the accuracy for those CPT codes in v13 and see if accuracy decreased when looking at individual sections\n",
    "    * Add option to run the code without stratifying by section\n",
    "* Complete model to predict CPT and ICD codes with their probabilities\n",
    "* Serialize the model to be used in streamlit\n",
    "* Add loading statements with time it module times for how long each section takes to run\n",
    "* Add HCC code that suggests HCC's based on the output\n",
    "* Add descriptions for the ICD and CPT code predictions\n",
    "* Add top most predictive feature names for the model in the output\n",
    "* Use label encoder and then reverse transform the encoded values\n",
    "\n",
    "Extra:\n",
    "* Add K-Means clustering to add suggested codes based on CPT and ICD code output\n",
    "* Add the model to a class with functions as methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-sharing",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('.\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-literature",
   "metadata": {},
   "source": [
    "# Assign Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "delayed-moscow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CPTEVENTS', 'DIAGNOSES_ICD', 'D_CPT', 'D_ICD_DIAGNOSES', 'D_ICD_PROCEDURES', 'NOTEEVENTS', 'PATIENTS', 'PROCEDURES_ICD'])\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573146 entries, 0 to 573145\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ROW_ID            573146 non-null  int64  \n",
      " 1   SUBJECT_ID        573146 non-null  int64  \n",
      " 2   HADM_ID           573146 non-null  int64  \n",
      " 3   COSTCENTER        573146 non-null  object \n",
      " 4   CHARTDATE         101545 non-null  object \n",
      " 5   CPT_CD            573146 non-null  object \n",
      " 6   CPT_NUMBER        573128 non-null  float64\n",
      " 7   CPT_SUFFIX        22 non-null      object \n",
      " 8   TICKET_ID_SEQ     471601 non-null  float64\n",
      " 9   SECTIONHEADER     573146 non-null  object \n",
      " 10  SUBSECTIONHEADER  573125 non-null  object \n",
      " 11  DESCRIPTION       101545 non-null  object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 52.5+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 651047 entries, 0 to 651046\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   ROW_ID      651047 non-null  int64  \n",
      " 1   SUBJECT_ID  651047 non-null  int64  \n",
      " 2   HADM_ID     651047 non-null  int64  \n",
      " 3   SEQ_NUM     651000 non-null  float64\n",
      " 4   ICD9_CODE   651000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 24.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134 entries, 0 to 133\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ROW_ID               134 non-null    int64 \n",
      " 1   CATEGORY             134 non-null    int64 \n",
      " 2   SECTIONRANGE         134 non-null    object\n",
      " 3   SECTIONHEADER        134 non-null    object\n",
      " 4   SUBSECTIONRANGE      134 non-null    object\n",
      " 5   SUBSECTIONHEADER     134 non-null    object\n",
      " 6   CODESUFFIX           11 non-null     object\n",
      " 7   MINCODEINSUBSECTION  134 non-null    int64 \n",
      " 8   MAXCODEINSUBSECTION  134 non-null    int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14567 entries, 0 to 14566\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       14567 non-null  int64 \n",
      " 1   ICD9_CODE    14567 non-null  object\n",
      " 2   SHORT_TITLE  14567 non-null  object\n",
      " 3   LONG_TITLE   14567 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 455.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3882 entries, 0 to 3881\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       3882 non-null   int64 \n",
      " 1   ICD9_CODE    3882 non-null   int64 \n",
      " 2   SHORT_TITLE  3882 non-null   object\n",
      " 3   LONG_TITLE   3882 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 121.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2083180 entries, 0 to 2083179\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   ROW_ID       int64  \n",
      " 1   SUBJECT_ID   int64  \n",
      " 2   HADM_ID      float64\n",
      " 3   CHARTDATE    object \n",
      " 4   CHARTTIME    object \n",
      " 5   STORETIME    object \n",
      " 6   CATEGORY     object \n",
      " 7   DESCRIPTION  object \n",
      " 8   CGID         float64\n",
      " 9   ISERROR      float64\n",
      " 10  TEXT         object \n",
      "dtypes: float64(3), int64(2), object(6)\n",
      "memory usage: 174.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46520 entries, 0 to 46519\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ROW_ID       46520 non-null  int64 \n",
      " 1   SUBJECT_ID   46520 non-null  int64 \n",
      " 2   GENDER       46520 non-null  object\n",
      " 3   DOB          46520 non-null  object\n",
      " 4   DOD          15759 non-null  object\n",
      " 5   DOD_HOSP     9974 non-null   object\n",
      " 6   DOD_SSN      13378 non-null  object\n",
      " 7   EXPIRE_FLAG  46520 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240095 entries, 0 to 240094\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   ROW_ID      240095 non-null  int64\n",
      " 1   SUBJECT_ID  240095 non-null  int64\n",
      " 2   HADM_ID     240095 non-null  int64\n",
      " 3   SEQ_NUM     240095 non-null  int64\n",
      " 4   ICD9_CODE   240095 non-null  int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 9.2 MB\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1384668da6e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# CPTEVENTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SECTIONHEADER'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'CPT_CD'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CPTEVENTS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CHARTDATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5460\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5461\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_datetime'"
     ]
    }
   ],
   "source": [
    "# Check all the datasets exist in the dictionary \n",
    "print(dataset_dictionary.keys())\n",
    "\n",
    "# Check the datatypes and information for each table \n",
    "for i in dataset_dictionary.keys():\n",
    "    print(dataset_dictionary[i].info())\n",
    "\n",
    "# Correct any datatype issues #####\n",
    "\n",
    "# CPTEVENTS\n",
    "dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']] = dataset_dictionary['CPTEVENTS'].loc[:,['SECTIONHEADER','CPT_CD']].astype(str)\n",
    "dataset_dictionary['CPTEVENTS']['CHARTDATE'] = dataset_dictionary['CPTEVENTS']['CHARTDATE'].to_datetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-raise",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - CPTEVENTS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "pediatric-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      687\n",
      "Emerging technology              22\n",
      "Evaluation and management    404388\n",
      "Medicine                     114194\n",
      "Pathology and laboratory         53\n",
      "Radiology                      2974\n",
      "Surgery                       50807\n",
      "nan                              21\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Total Unique CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      5\n",
      "Emerging technology             8\n",
      "Evaluation and management      58\n",
      "Medicine                       91\n",
      "Pathology and laboratory        4\n",
      "Radiology                      61\n",
      "Surgery                      1784\n",
      "nan                             7\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      " Section Header: Anesthesia \n",
      "\n",
      "count      5.000000\n",
      "mean     137.400000\n",
      "std      243.206291\n",
      "min        2.000000\n",
      "25%       21.000000\n",
      "50%       37.000000\n",
      "75%       56.000000\n",
      "max      571.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Emerging technology \n",
      "\n",
      "count    8.00000\n",
      "mean     2.75000\n",
      "std      2.54951\n",
      "min      1.00000\n",
      "25%      1.00000\n",
      "50%      1.50000\n",
      "75%      3.50000\n",
      "max      8.00000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Evaluation and management \n",
      "\n",
      "count        58.000000\n",
      "mean       6972.206897\n",
      "std       22252.229542\n",
      "min           1.000000\n",
      "25%           7.000000\n",
      "50%          32.500000\n",
      "75%         963.250000\n",
      "max      108434.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Medicine \n",
      "\n",
      "count       91.000000\n",
      "mean      1254.879121\n",
      "std       9325.079213\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          5.000000\n",
      "75%         15.000000\n",
      "max      87984.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Pathology and laboratory \n",
      "\n",
      "count     4.000000\n",
      "mean     13.250000\n",
      "std      19.534158\n",
      "min       1.000000\n",
      "25%       1.000000\n",
      "50%       5.000000\n",
      "75%      17.250000\n",
      "max      42.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Radiology \n",
      "\n",
      "count      61.000000\n",
      "mean       48.754098\n",
      "std       179.448475\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         5.000000\n",
      "75%        17.000000\n",
      "max      1050.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: Surgery \n",
      "\n",
      "count    1784.000000\n",
      "mean       28.479260\n",
      "std       168.369641\n",
      "min         1.000000\n",
      "25%         1.000000\n",
      "50%         3.000000\n",
      "75%        11.000000\n",
      "max      4150.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      " Section Header: nan \n",
      "\n",
      "count    7.000000\n",
      "mean     3.000000\n",
      "std      2.236068\n",
      "min      1.000000\n",
      "25%      1.500000\n",
      "50%      2.000000\n",
      "75%      4.000000\n",
      "max      7.000000\n",
      "Name: CPT_CD, dtype: float64\n",
      "\n",
      "Total Unique CPT counts per section\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                      5\n",
      "Emerging technology             8\n",
      "Evaluation and management      58\n",
      "Medicine                       91\n",
      "Pathology and laboratory        4\n",
      "Radiology                      60\n",
      "Surgery                      1758\n",
      "nan                             7\n",
      "Name: CPT_CD, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many CPT codes are in the data for each CPT section? -----\n",
    "data_cpt = dataset_dictionary['CPTEVENTS']\n",
    "print('\\nTotal CPT counts per section\\n\\n', data_cpt.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# How many unique CPT codes are there per CPT section? -----\n",
    "data_nodups = data_cpt.loc[:,['CPT_CD', 'SECTIONHEADER']].drop_duplicates()\n",
    "print('\\nTotal Unique CPT counts per section\\n\\n', data_nodups.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# What is the distribution of counts for each CPT code per section? -----\n",
    "for i in np.unique(data_cpt['SECTIONHEADER']):\n",
    "    print('\\n Section Header:',i,'\\n')\n",
    "    print(data_cpt[data_cpt['SECTIONHEADER'] == i].groupby('CPT_CD')['CPT_CD'].count().describe())\n",
    "    \n",
    "# How many unique CPT codes are there per CPT section when filtered to the Discharge Summary Section in the Note Events Table? -----\n",
    "data_notes = dataset_dictionary['NOTEEVENTS']\n",
    "data_notes = data_notes[data_notes['CATEGORY'] == 'Discharge summary']\n",
    "data_merged = data_notes.merge(data_cpt, on = ['SUBJECT_ID','HADM_ID'])\n",
    "data_nodups = data_merged.loc[:,['CPT_CD', 'SECTIONHEADER']].drop_duplicates()\n",
    "print('\\nTotal Unique CPT counts per section\\n\\n', data_nodups.groupby('SECTIONHEADER')['CPT_CD'].count())\n",
    "\n",
    "# Are there multiple CPT codes per encounter? -----\n",
    "# Answer: Yes\n",
    "\n",
    "data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "\n",
    "# What percentage of encounters only have one CPT code?\n",
    "# Answer: 8.3%\n",
    "data_grouped = data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "(data_grouped == 1).sum()/ len(np.unique(data_cpt['HADM_ID']))\n",
    "\n",
    "# What does the distribution look like for number of CPT codes per encounter?\n",
    "data_grouped = data_cpt.groupby('HADM_ID')['CPT_CD'].count()\n",
    "plt.hist(data_grouped, bins=range(21))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-nursing",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - NOTEEVENTS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "willing-israel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Case Management ' 'Consult' 'Discharge summary' 'ECG' 'Echo' 'General'\n",
      " 'Nursing' 'Nursing/other' 'Nutrition' 'Pharmacy' 'Physician ' 'Radiology'\n",
      " 'Rehab Services' 'Respiratory ' 'Social Work']\n",
      "Chief Complaint:\n",
      "   24 Hour Events:\n",
      " Continued to be anuric.  Tolerated HD well.  Decision today by pt and\n",
      "   wife to convert to [**Name (NI) 617**].\n",
      "   History obtained from Patient\n",
      "   Allergies:\n",
      "   History obtained from PatientHeparin Agents\n",
      "   Thrombocytopeni\n",
      "   Last dose of Antibiotics:\n",
      "   Piperacillin - [**2138-3-20**] 08:00 PM\n",
      "   Piperacillin/Tazobactam (Zosyn) - [**2138-3-21**] 09:00 AM\n",
      "   Metronidazole - [**2138-3-21**] 10:12 AM\n",
      "   Infusions:\n",
      "   Other ICU medications:\n",
      "   Other medications:\n",
      "   Changes to medical and family history:\n",
      "   Review of systems is unchanged from admission except as noted below\n",
      "   Review of systems:\n",
      "   Flowsheet Data as of  [**2138-3-21**] 02:56 PM\n",
      "   Vital signs\n",
      "   Hemodynamic monitoring\n",
      "   Fluid balance\n",
      "                                                                  24 hours\n",
      "                                                               Since 12 AM\n",
      "   Tmax: 36.6\n",
      "C (97.9\n",
      "   Tcurrent: 36.1\n",
      "C (96.9\n",
      "   HR: 113 (103 - 115) bpm\n",
      "   BP: 106/58(71){91/45(58) - 106/67(76)} mmHg\n",
      "   RR: 23 (16 - 26) insp/min\n",
      "   SpO2: 100%\n",
      "   Heart rhythm: ST (Sinus Tachycardia)\n",
      "   Height: 72 Inch\n",
      "             Total In:\n",
      "                                                                    700 mL\n",
      "                                                                    569 mL\n",
      "   PO:\n",
      "                                                                    200 mL\n",
      "                                                                    220 mL\n",
      "   TF:\n",
      "   IVF:\n",
      "                                                                    500 mL\n",
      "                                                                    349 mL\n",
      "   Blood products:\n",
      "   Total out:\n",
      "                                                                     43 mL\n",
      "                                                                    163 mL\n",
      "   Urine:\n",
      "                                                                     43 mL\n",
      "                                                                     18 mL\n",
      "   NG:\n",
      "   Stool:\n",
      "   Drains:\n",
      "   Balance:\n",
      "                                                                    657 mL\n",
      "                                                                    406 mL\n",
      "   Respiratory support\n",
      "   O2 Delivery Device: None\n",
      "   SpO2: 100%\n",
      "   ABG: ///19/\n",
      "   Physical Examination\n",
      "   General Appearance: No acute distress\n",
      "   Head, Ears, Nose, Throat: Normocephalic\n",
      "   Cardiovascular: (S1: Normal), (S2: Normal), (Murmur: Systolic)\n",
      "   Peripheral Vascular: (Right radial pulse: Not assessed), (Left radial\n",
      "   pulse: Not assessed), (Right DP pulse: Not assessed), (Left DP pulse:\n",
      "   Not assessed)\n",
      "   Respiratory / Chest: (Expansion: Symmetric), (Breath Sounds: Clear : )\n",
      "   Abdominal: Soft, Non-tender, Bowel sounds present\n",
      "   Extremities: Right: 1+, Left: 1+\n",
      "   Musculoskeletal: Unable to stand\n",
      "   Skin:  Not assessed\n",
      "   Neurologic: Attentive, Follows simple commands, Responds to: Not\n",
      "   assessed, Movement: Not assessed, Tone: Not assessed\n",
      "   Labs / Radiology\n",
      "   233 K/uL\n",
      "   8.5 g/dL\n",
      "   173 mg/dL\n",
      "   4.4 mg/dL\n",
      "   19 mEq/L\n",
      "   4.3 mEq/L\n",
      "   87 mg/dL\n",
      "   111 mEq/L\n",
      "   143 mEq/L\n",
      "   27.8 %\n",
      "   5.1 K/uL\n",
      "        [image002.jpg]\n",
      "                             [**2138-3-17**]  07:46 PM\n",
      "                             [**2138-3-18**]  05:42 AM\n",
      "                             [**2138-3-18**]  01:56 PM\n",
      "                             [**2138-3-19**]  05:59 AM\n",
      "                             [**2138-3-19**]  04:41 PM\n",
      "                             [**2138-3-19**]  08:27 PM\n",
      "                             [**2138-3-20**]  04:52 AM\n",
      "                             [**2138-3-20**]  04:38 PM\n",
      "                             [**2138-3-21**]  04:37 AM\n",
      "   WBC\n",
      "   14.8\n",
      "   5.0\n",
      "   6.1\n",
      "   5.8\n",
      "   5.1\n",
      "   Hct\n",
      "   31.8\n",
      "   28.8\n",
      "   28.7\n",
      "   28.0\n",
      "   27.8\n",
      "   Plt\n",
      "   [**Telephone/Fax (3) 745**]85\n",
      "   233\n",
      "   Cr\n",
      "   4.5\n",
      "   4.3\n",
      "   4.5\n",
      "   4.5\n",
      "   4.8\n",
      "   4.9\n",
      "   5.2\n",
      "   4.2\n",
      "   4.4\n",
      "   TropT\n",
      "   0.42\n",
      "   0.35\n",
      "   0.33\n",
      "   Glucose\n",
      "   [**Telephone/Fax (3) 696**]64\n",
      "   163\n",
      "   152\n",
      "   208\n",
      "   173\n",
      "   Other labs: PT / PTT / INR:13.9/32.0/1.2, CK / CKMB /\n",
      "   Troponin-T:10/4/0.33, Amylase / Lipase:45/34, Differential-Neuts:94.1\n",
      "   %, Band:Units: %\n",
      "   Range: 0-5 %, Lymph:4.2 %, Mono:1.6 %, Eos:Units: %\n",
      "   Range: 0-4 %, Fibrinogen:399 mg/dL, Lactic Acid:1.0 mmol/L, Albumin:2.1\n",
      "   g/dL, Ca++:8.1 mg/dL, Mg++:1.9 mg/dL, PO4:5.5 mg/dL\n",
      "   Assessment and Plan\n",
      "   1. [**Telephone/Fax (3) 617**]: Pt and wife desired to transition to [**Name (NI) 617**] today; palliative care\n",
      "   following.  Review palliative care recs.\n",
      "   2.  Renal failure:  Anuric, s/p HD yesterday, scheduled for HD today\n",
      "   and tomorrow per renal; however, pt and wife now want to stop HD. Cr\n",
      "   down to 4.4 from 5.2 and K+ 4.4 from 5.2.\n",
      "   3.  Pulmonary Edema:  Worsened on CXR from yesterday, no subjective\n",
      "   dyspnea.  No crackles heard on anterior exam as fluid is dependant.\n",
      "   Cause is multifactorial including pseudomonal UTI likely resulting in\n",
      "   sepsis, poor nutritional status, low EF of 40% and aortic stenosis.  Pt\n",
      "   now [**Name (NI) 617**].\n",
      "   4. ESRD:  S/p B renal transplant, on tacrolimus and steriods.  Now [**Name (NI) 617**],\n",
      "   d/c tacrolimus and steroids.\n",
      "   5.  Pseudomonal UTI:  Now [**Name (NI) 617**].\n",
      "   6.  Fever/Hypotension:  Resolved.  Pt now [**Name (NI) 617**], d/c all antibiotics.\n",
      "   7.  Prostate Cancer:  [**Name (NI) 617**].  D/c Lupron.\n",
      "   ICU Care:  PT NOW [**Name (NI) 617**].\n",
      "   Nutrition:\n",
      "   Glycemic Control:\n",
      "   Lines:\n",
      "   Presep Catheter - [**2138-3-17**] 03:30 PM\n",
      "   Prophylaxis:\n",
      "   DVT:\n",
      "   Stress ulcer:\n",
      "   VAP:\n",
      "   Comments:\n",
      "   Communication:  Comments:\n",
      "   Code status: DNR / DNI ; [**Year (4 digits) 617**]\n",
      "   Disposition:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "Case Management         967\n",
       "Consult                  98\n",
       "Discharge summary     59652\n",
       "ECG                  209051\n",
       "Echo                  45794\n",
       "General                8301\n",
       "Nursing              223556\n",
       "Nursing/other        822497\n",
       "Nutrition              9418\n",
       "Pharmacy                103\n",
       "Physician            141624\n",
       "Radiology            522279\n",
       "Rehab Services         5431\n",
       "Respiratory           31739\n",
       "Social Work            2670\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset_dictionary['NOTEEVENTS']\n",
    "\n",
    "# What are the unique categories?\n",
    "print(np.unique(data['CATEGORY']))\n",
    "\n",
    "# What do some of the notes look like in each category?\n",
    "print(data[data['CATEGORY'] == 'Physician ']['TEXT'].iloc[0])\n",
    "\n",
    "# How many notes are there per category?\n",
    "data.groupby('CATEGORY')['CATEGORY'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-b91f3608699f>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['DESCRIPTION'] = ''\n"
     ]
    }
   ],
   "source": [
    "def join_tables(dataset_dictionary, category=['Discharge summary'], all_notes=False):\n",
    "\n",
    "    # Define tables\n",
    "    note_events_base = dataset_dictionary['NOTEEVENTS']\n",
    "    cpt_events_base = dataset_dictionary['CPTEVENTS']\n",
    "    \n",
    "    # Combine text for each subject and encounter\n",
    "    if all_notes == False:\n",
    "        note_events_base = note_events_base[note_events_base.loc[:,'CATEGORY'].isin(category)]\n",
    "\n",
    "    note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "    \n",
    "    # Create CPT table\n",
    "    cpt_events_base = cpt_events_base.loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD', 'SECTIONHEADER', 'DESCRIPTION']]\n",
    "    cpt_events = cpt_events_base.drop_duplicates()\n",
    "    \n",
    "    # Join the datasets\n",
    "    note_cpt = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "    \n",
    "    # Replace any nulls with blanks\n",
    "    x = note_cpt[note_cpt['DESCRIPTION'].isnull()]\n",
    "    x['DESCRIPTION'] = ''\n",
    "    y = note_cpt[note_cpt['DESCRIPTION'].notnull()]\n",
    "    note_cpt = pd.concat([x,y])\n",
    "    \n",
    "    # Combine description and text columns\n",
    "    note_cpt['TEXT'] = note_cpt['TEXT'] + note_cpt['DESCRIPTION']\n",
    "    note_cpt = note_cpt.drop('DESCRIPTION', axis=1)\n",
    "    \n",
    "    return note_cpt\n",
    "    \n",
    "note_cpt = join_tables(dataset_dictionary)\n",
    "# ['Consult','Discharge summary','General', 'Nursing', 'Nursing/other'\\\n",
    "#                                             , 'Physician ','Rehab Services','Respiratory ']\n",
    "\n",
    "# Drop notes with the nan sectionheader\n",
    "drop_ls = note_cpt[note_cpt['SECTIONHEADER'] == 'nan']\n",
    "note_cpt = note_cpt.drop(drop_ls.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-adelaide",
   "metadata": {},
   "source": [
    "# Join the Tables - Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "covered-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SUBJECT_ID   HADM_ID  \\\n",
      "68809       20785  199993.0   \n",
      "68810       20785  199993.0   \n",
      "68811       20785  199993.0   \n",
      "68812       20785  199993.0   \n",
      "68813       20785  199993.0   \n",
      "68814       20785  199993.0   \n",
      "\n",
      "                                                    TEXT CPT_CD  \\\n",
      "68809  Admission Date:  [**2161-10-23**]       Discha...  99291   \n",
      "68810  Admission Date:  [**2161-10-23**]       Discha...  99252   \n",
      "68811  Admission Date:  [**2161-10-23**]       Discha...  99262   \n",
      "68812  Admission Date:  [**2161-10-23**]       Discha...  99232   \n",
      "68813  Admission Date:  [**2161-10-23**]       Discha...  94003   \n",
      "68814  Admission Date:  [**2161-10-23**]       Discha...  94002   \n",
      "\n",
      "                   SECTIONHEADER  \n",
      "68809  Evaluation and management  \n",
      "68810  Evaluation and management  \n",
      "68811  Evaluation and management  \n",
      "68812  Evaluation and management  \n",
      "68813                   Medicine  \n",
      "68814                   Medicine  \n",
      "        SUBJECT_ID  HADM_ID CPT_CD              SECTIONHEADER\n",
      "4130         20785   199993  99291  Evaluation and management\n",
      "4131         20785   199993  99252  Evaluation and management\n",
      "4133         20785   199993  99262  Evaluation and management\n",
      "4134         20785   199993  99232  Evaluation and management\n",
      "517255       20785   199993  94003                   Medicine\n",
      "517259       20785   199993  94002                   Medicine\n"
     ]
    }
   ],
   "source": [
    "# Check the base table against the new table after joins\n",
    "print(note_cpt[note_cpt['HADM_ID'] == 199993])\n",
    "data = dataset_dictionary['CPTEVENTS']\n",
    "print(data[data['HADM_ID'] == 199993].loc[:,['SUBJECT_ID','HADM_ID', 'CPT_CD', 'SECTIONHEADER']].drop_duplicates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-dealing",
   "metadata": {},
   "source": [
    "# Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pursuant-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(combined_df, threshold):\n",
    "\n",
    "    # Print value counts original\n",
    "    print('Value Counts for the original data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    # Filter based on count limit\n",
    "    df = combined_df['CPT_CD'].value_counts()\n",
    "    filtered_ls = list((df[df >= threshold]).index.values)\n",
    "    filtered_df = combined_df[combined_df['CPT_CD'].isin(filtered_ls)]\n",
    "    \n",
    "    # Print value counts filtered\n",
    "    print('Value Counts for the filtered data:\\n\\n', combined_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Find Counts of CPT Codes per Patient Encounter and filter df\n",
    "def cpt_count_filter(df, og_df, limit):\n",
    "\n",
    "    og_df = og_df.groupby(['HADM_ID', 'SECTIONHEADER'])['CPT_CD'].count()\n",
    "    filtered_encntrs = og_df[og_df <= limit]\n",
    "    final_df = df.merge(filtered_encntrs, on='HADM_ID')\n",
    "    final_df.drop('CPT_CD_y', axis=1, inplace=True)\n",
    "    final_df.columns = ['SUBJECT_ID', 'HADM_ID', 'TEXT', 'CPT_CD', 'SECTIONHEADER']\n",
    "    \n",
    "    print('Value Counts for the filtered data:\\n\\n', final_df['CPT_CD'].value_counts().head(25))\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Filter DataFrame to a set amount of CPT codes in each section header #####\n",
    "def cpt_per_section_filter(df, section_limit, sections=['Emerging technology'], all_sections=False):\n",
    "    \n",
    "    # Create list for dataframes\n",
    "    df_ls = []\n",
    "\n",
    "    # Group by and count the number of CPT codes\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_cpt.index.names = ['SECTIONHEADER', 'CPT_CDS']\n",
    "    cts_by_cpt = cts_by_cpt.reset_index()\n",
    "    cts_by_cpt.columns = ['SECTIONHEADER', 'CPT_CD', 'COUNT']\n",
    "\n",
    "    # Sort values by section and CPT code count\n",
    "    cts_by_cpt_s = cts_by_cpt.sort_values(by=['SECTIONHEADER','COUNT'], ascending=False)\n",
    "\n",
    "    # Filter based on the limit of CPT codes wanted for each category\n",
    "    if all_sections == True:\n",
    "        sections = list(set(df['SECTIONHEADER']))\n",
    "        \n",
    "    for i in sections:\n",
    "        top_cts = cts_by_cpt_s[cts_by_cpt_s['SECTIONHEADER'] == i].iloc[:section_limit,:]\n",
    "\n",
    "        # Append to list\n",
    "        df_ls.append(top_cts)\n",
    "\n",
    "    # Combine DataFrames\n",
    "    df_combo = pd.concat(df_ls)\n",
    "\n",
    "    # Join back to source data\n",
    "    final_df = df.merge(df_combo, on=['SECTIONHEADER','CPT_CD'])\n",
    "    \n",
    "    print('\\nThe length of the initial dataset was {} and the new dataset is {}\\n\\n'.format(len(df), len(final_df)))\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def show_section_counts(df):\n",
    "    # Print count of CPT codes by section\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    cts_by_section = cts_by_cpt.groupby('SECTIONHEADER').count()\n",
    "    print('\\nHere are the counts by section:\\n\\n', cts_by_section)\n",
    "\n",
    "def show_cpt_counts_by_section(df):\n",
    "    cts_by_cpt = df.groupby(['SECTIONHEADER', 'CPT_CD'])['CPT_CD'].count()\n",
    "    print('\\nHere are the counts by CPT by section\\n\\n:', cts_by_cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "encouraging-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for the filtered data:\n",
      "\n",
      " 99291    14323\n",
      "94003    13465\n",
      "99232    11565\n",
      "99233    10603\n",
      "94002     7077\n",
      "99231     6689\n",
      "99254     4648\n",
      "99223     4526\n",
      "99239     3496\n",
      "99222     3382\n",
      "36556     3371\n",
      "99255     3270\n",
      "99253     3180\n",
      "99292     2724\n",
      "99238     2328\n",
      "99252     1326\n",
      "90935     1318\n",
      "36620     1305\n",
      "33533     1208\n",
      "33508     1204\n",
      "76942     1184\n",
      "76937     1174\n",
      "31624     1011\n",
      "31645      870\n",
      "99221      824\n",
      "Name: CPT_CD, dtype: int64\n",
      "Available sections:\n",
      "\n",
      " {'Pathology and laboratory', 'Evaluation and management', 'Emerging technology', 'Anesthesia', 'Radiology', 'Surgery', 'Medicine'}\n",
      "\n",
      "The length of the initial dataset was 131592 and the new dataset is 103826\n",
      "\n",
      "\n",
      "\n",
      "Here are the counts by section:\n",
      "\n",
      " SECTIONHEADER\n",
      "Anesthesia                    5\n",
      "Emerging technology           8\n",
      "Evaluation and management    10\n",
      "Medicine                     10\n",
      "Pathology and laboratory      4\n",
      "Radiology                    10\n",
      "Surgery                      10\n",
      "Name: CPT_CD, dtype: int64\n",
      "\n",
      "Here are the counts by CPT by section\n",
      "\n",
      ": SECTIONHEADER              CPT_CD\n",
      "Anesthesia                 01996       367\n",
      "                           99141        62\n",
      "                           99143         2\n",
      "                           99144        48\n",
      "                           99145         5\n",
      "Emerging technology        0050T         2\n",
      "                           0078T         1\n",
      "                           0079T         1\n",
      "                           0080T         1\n",
      "                           0081T         1\n",
      "                           0256T         9\n",
      "                           0257T         7\n",
      "                           0258T         2\n",
      "Evaluation and management  99222      3382\n",
      "                           99223      4526\n",
      "                           99231      6689\n",
      "                           99232     11565\n",
      "                           99233     10603\n",
      "                           99239      3496\n",
      "                           99253      3180\n",
      "                           99254      4648\n",
      "                           99255      3270\n",
      "                           99291     14323\n",
      "Medicine                   90801       272\n",
      "                           90935      1318\n",
      "                           90937       166\n",
      "                           90945       336\n",
      "                           92960       118\n",
      "                           93503       217\n",
      "                           93886        63\n",
      "                           94002      7077\n",
      "                           94003     13465\n",
      "                           99024       205\n",
      "Pathology and laboratory   82801         2\n",
      "                           82803        14\n",
      "                           82805         2\n",
      "                           85060        67\n",
      "Radiology                  75710        50\n",
      "                           75940       150\n",
      "                           75952        24\n",
      "                           75960        49\n",
      "                           75989        49\n",
      "                           76604       135\n",
      "                           76937      1174\n",
      "                           76942      1184\n",
      "                           77001        23\n",
      "                           77071        77\n",
      "Surgery                    31500       466\n",
      "                           31600       490\n",
      "                           31622       723\n",
      "                           31624      1011\n",
      "                           31645       870\n",
      "                           33405       751\n",
      "                           33508      1204\n",
      "                           33533      1208\n",
      "                           36556      3371\n",
      "                           36620      1305\n",
      "Name: CPT_CD, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the number of CPT occurrences by section and CPT\n",
    "filtered_df1 = cpt_count_filter(note_cpt, note_cpt, 1)\n",
    "\n",
    "# Filter the number of CPT codes in each section #####\n",
    "\n",
    "# Show available sections\n",
    "print('Available sections:\\n\\n', set(filtered_df1['SECTIONHEADER']))\n",
    "\n",
    "# Set sections\n",
    "sections = ['Emerging Technology', 'Anesthesia']\n",
    "\n",
    "# Run Functions\n",
    "filtered_df = cpt_per_section_filter(filtered_df1, 10, all_sections=True)\n",
    "show_section_counts(filtered_df)\n",
    "show_cpt_counts_by_section(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-juice",
   "metadata": {},
   "source": [
    "# Filter the Data - Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cleared-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610\n",
      "1984\n",
      "count    42701.000000\n",
      "mean         5.238519\n",
      "std          3.553827\n",
      "min          1.000000\n",
      "25%          3.000000\n",
      "50%          5.000000\n",
      "75%          7.000000\n",
      "max         55.000000\n",
      "Name: CPT_CD, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "223690"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPSUlEQVR4nO3dbaykZX3H8e+vrGDj0wqcELK79WClNrypkI2l8SGN1JYH69JWDcbo1tJsmmCisY1da9LapC+gTaU1MRpaiKuxgvUhbFybShFr+gJ0weVZ5Egh7GZhV0S0sdqi/76Y69jheGbPw56ZOXud7yeZzHVf9zVz/881s7+55557ZlNVSJL68nPTLkCStPYMd0nqkOEuSR0y3CWpQ4a7JHVo07QLADj99NNrdnZ22mVI0gnl9ttv/3ZVzSy2bl2E++zsLPv37592GZJ0QknyyKh1HpaRpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOdRPus7v3TbsESVo3ugl3SdL/M9wlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0LLDPclJSb6e5PNt+awktyWZS3JDkpNb/yltea6tnx1T7ZKkEVay5/5O4P6h5auAq6vqJcCTwOWt/3LgydZ/dRsnSZqgZYV7kq3AJcA/tuUArwE+3YbsAS5t7R1tmbb+gjZekjQhy91z/zvgPcBP2vJpwHer6um2fBDY0tpbgEcB2vqn2vhnSLIryf4k+48ePbq66iVJi1oy3JO8DjhSVbev5Yar6pqq2l5V22dmZtbyriVpw9u0jDGvAF6f5GLg2cDzgb8HNifZ1PbOtwKH2vhDwDbgYJJNwAuAJ9a8cknSSEvuuVfVe6tqa1XNApcBX6qqtwC3AG9ow3YCN7b23rZMW/+lqqo1rVqSdEzHc577nwLvTjLH4Jj6ta3/WuC01v9uYPfxlShJWqnlHJb5qar6MvDl1n4IePkiY34IvHENapMkrZLfUJWkDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SerQkuGe5NlJvprkziT3JvnL1n9WktuSzCW5IcnJrf+UtjzX1s+O+W+QJC2wnD33HwGvqapfAV4GXJjkfOAq4OqqegnwJHB5G3858GTrv7qNkyRN0JLhXgP/1Raf1S4FvAb4dOvfA1za2jvaMm39BUmyVgVLkpa2rGPuSU5KcgA4AtwEfAv4blU93YYcBLa09hbgUYC2/ingtDWsWZK0hGWFe1X9uKpeBmwFXg788vFuOMmuJPuT7D969Ojx3p0kaciKzpapqu8CtwC/BmxOsqmt2gocau1DwDaAtv4FwBOL3Nc1VbW9qrbPzMysrnpJ0qKWc7bMTJLNrf3zwGuB+xmE/BvasJ3Aja29ty3T1n+pqmoNa5YkLWHT0kM4E9iT5CQGLwafqqrPJ7kPuD7JXwFfB65t468FPp5kDvgOcNkY6pYkHcOS4V5VdwHnLtL/EIPj7wv7fwi8cU2qkyStit9QlaQOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA51Fe6zu/cxu3vftMuQpKnrKtwlSQOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktShJcM9ybYktyS5L8m9Sd7Z+k9NclOSB9v1C1t/knwwyVySu5KcN+4/QpL0TMvZc38a+OOqOgc4H7giyTnAbuDmqjobuLktA1wEnN0uu4APr3nVkqRjWjLcq+pwVd3R2t8H7ge2ADuAPW3YHuDS1t4BfKwGbgU2JzlzrQuXJI22omPuSWaBc4HbgDOq6nBb9RhwRmtvAR4dutnB1rfwvnYl2Z9k/9GjR1datyTpGJYd7kmeC3wGeFdVfW94XVUVUCvZcFVdU1Xbq2r7zMzMSm4qSVrCssI9ybMYBPsnquqzrfvx+cMt7fpI6z8EbBu6+dbWJ0makOWcLRPgWuD+qvrA0Kq9wM7W3gncONT/tnbWzPnAU0OHbyRJE7BpGWNeAbwVuDvJgdb3Z8CVwKeSXA48AryprfsCcDEwB/wAePtaFixJWtqS4V5V/wFkxOoLFhlfwBXHWZck6Tj4DVVJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6lCX4T67e9+0S5Ckqeoy3CVpozPcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDi0Z7kmuS3IkyT1DfacmuSnJg+36ha0/ST6YZC7JXUnOG2fxkqTFLWfP/aPAhQv6dgM3V9XZwM1tGeAi4Ox22QV8eG3KlCStxJLhXlVfAb6zoHsHsKe19wCXDvV/rAZuBTYnOXONapUkLdNqj7mfUVWHW/sx4IzW3gI8OjTuYOv7GUl2JdmfZP/Ro0dXWYYkaTHH/YFqVRVQq7jdNVW1vaq2z8zMHG8ZkqQhqw33x+cPt7TrI63/ELBtaNzW1idJmqDVhvteYGdr7wRuHOp/Wztr5nzgqaHDN5KkCdm01IAknwR+HTg9yUHgL4ArgU8luRx4BHhTG/4F4GJgDvgB8PYx1CxJWsKS4V5Vbx6x6oJFxhZwxfEWtZZmd+/j4SsvmXYZkjRRfkNVkjpkuEtSh5Y8LHOimt29b9olSNLUuOcuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1aEOE++zuff7WjKQNZUOEuyRtNIa7JHXIcJekDhnuktQhw12SOrShwt2zZiRtFBsq3CVpozDcJalDhrskdWjDhrvH3yX1bMOGuyT1bEOGu3vsknq3IcNdknq3adoFTNvwXvzDV14yxUokae245z7EwzWSemG4S1KHDHdJ6pDhvoDnv0vqgeEuSR3a8GfLjLJw790zaSSdSNxzXyYP10g6kRjuK2TASzoRGO6rMLwXP6q92NhxbF+SFjOWcE9yYZIHkswl2T2Obaw3w2E7H74L+xaOXyygVxvcy9nmqFol9WfNP1BNchLwIeC1wEHga0n2VtV9a72taVtpMC41fmHozn+Iu5LbHWvMWn4ovJ5+tmGt/zapB+M4W+blwFxVPQSQ5HpgB9BduK+V5exhr2b9wjFLtR++8pJF28MWC9FRZxaNqm/UfS/H8H2PCvThv2GpOke9SB2r9oXbX86ZVSt5MVw4dtTfsxKjHtfl1LLYPI56HCb1or+SORnHfK62lklKVa3tHSZvAC6sqj9sy28FfrWq3rFg3C5gV1t8KfDAKjd5OvDtVd523NZrbda1Mta1cuu1tt7qelFVzSy2YmrnuVfVNcA1x3s/SfZX1fY1KGnNrdfarGtlrGvl1mttG6mucXygegjYNrS8tfVJkiZkHOH+NeDsJGclORm4DNg7hu1IkkZY88MyVfV0kncA/wqcBFxXVfeu9XaGHPehnTFar7VZ18pY18qt19o2TF1r/oGqJGn6/IaqJHXIcJekDp3Q4b5efuYgybYktyS5L8m9Sd7Z+t+f5FCSA+1y8RRqezjJ3W37+1vfqUluSvJgu37hhGt66dCcHEjyvSTvmtZ8JbkuyZEk9wz1LTpHGfhge87dleS8Cdf1N0m+0bb9uSSbW/9skv8emruPTLiukY9dkve2+XogyW+Nq65j1HbDUF0PJznQ+icyZ8fIh/E+x6rqhLww+LD2W8CLgZOBO4FzplTLmcB5rf084JvAOcD7gT+Z8jw9DJy+oO+vgd2tvRu4asqP42PAi6Y1X8CrgfOAe5aaI+Bi4F+AAOcDt024rt8ENrX2VUN1zQ6Pm8J8LfrYtX8HdwKnAGe1f7MnTbK2Bev/FvjzSc7ZMfJhrM+xE3nP/ac/c1BV/wPM/8zBxFXV4aq6o7W/D9wPbJlGLcu0A9jT2nuAS6dXChcA36qqR6ZVQFV9BfjOgu5Rc7QD+FgN3ApsTnLmpOqqqi9W1dNt8VYG3yOZqBHzNcoO4Pqq+lFV/Scwx+Df7sRrSxLgTcAnx7X9ETWNyoexPsdO5HDfAjw6tHyQdRCoSWaBc4HbWtc72lur6yZ9+KMp4ItJbs/gJx8Azqiqw639GHDGFOqadxnP/Mc27fmaN2qO1tPz7g8Y7OHNOyvJ15P8e5JXTaGexR679TRfrwIer6oHh/omOmcL8mGsz7ETOdzXnSTPBT4DvKuqvgd8GPhF4GXAYQZvCSftlVV1HnARcEWSVw+vrMH7wKmcD5vBl9xeD/xz61oP8/UzpjlHoyR5H/A08InWdRj4hao6F3g38E9Jnj/BktblY7fAm3nmjsRE52yRfPipcTzHTuRwX1c/c5DkWQweuE9U1WcBqurxqvpxVf0E+AfG+HZ0lKo61K6PAJ9rNTw+/zavXR+ZdF3NRcAdVfV4q3Hq8zVk1BxN/XmX5PeB1wFvaaFAO+zxRGvfzuDY9i9NqqZjPHZTny+AJJuA3wVumO+b5Jwtlg+M+Tl2Iof7uvmZg3Ys71rg/qr6wFD/8HGy3wHuWXjbMdf1nCTPm28z+DDuHgbztLMN2wncOMm6hjxjT2ra87XAqDnaC7ytndFwPvDU0FvrsUtyIfAe4PVV9YOh/pkM/i8FkrwYOBt4aIJ1jXrs9gKXJTklyVmtrq9Oqq4hvwF8o6oOzndMas5G5QPjfo6N+5PicV4YfKr8TQavuO+bYh2vZPCW6i7gQLtcDHwcuLv17wXOnHBdL2ZwpsKdwL3zcwScBtwMPAj8G3DqFObsOcATwAuG+qYyXwxeYA4D/8vg+Oblo+aIwRkMH2rPubuB7ROua47B8dj559lH2tjfa4/xAeAO4LcnXNfIxw54X5uvB4CLJv1Ytv6PAn+0YOxE5uwY+TDW55g/PyBJHTqRD8tIkkYw3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KH/g8daXbwxcR7nwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many unique CPT codes are there in each group? #####\n",
    "print(len(np.unique(filtered_df['CPT_CD'])))\n",
    "print(len(np.unique(note_cpt['CPT_CD'])))\n",
    "\n",
    "##### When not stratifying\n",
    "# 1,991 total codes and 121 codes where == 1 CPT codes\n",
    "# 1,991 total codes and 133 codes where <= 2 CPT codes\n",
    "# 1,991 total codes and 134 codes where <= 3 CPT codes\n",
    "\n",
    "### When stratifying by section header\n",
    "# 1984 total codes and 1610 codes where == 1 CPT codes\n",
    "# Only 374 codes are lost compared to 1870 codes\n",
    "\n",
    "# What is the distribution of CPT code counts?\n",
    "print(note_cpt.groupby('HADM_ID')['CPT_CD'].count().describe())\n",
    "plt.hist(filtered_df['CPT_CD'].value_counts(), bins=range(200))\n",
    "plt.show()\n",
    "\n",
    "# Length of the filtered data\n",
    "len(filtered_df) # 131,592\n",
    "len(note_cpt) # 223,690\n",
    "#### Lost about 90K records due to filtering and 374 CPT codes\n",
    "\n",
    "# What are the counts by the section headers?\n",
    "filtered_df['SECTIONHEADER'].value_counts()\n",
    "\n",
    "# Group by and count the number of CPT codes\n",
    "x = filtered_df.groupby(['SECTIONHEADER', 'CPT_CD'], as_index = False)['CPT_CD'].count()\n",
    "\n",
    "# How many CPT codes are there by section header?\n",
    "x.groupby('SECTIONHEADER').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text_series):\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)    \n",
    "\n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Remove topics\n",
    "    data = text_series.str.split('([A-Z\\s]+:)')\n",
    "    for row_num, value in enumerate(data):\n",
    "        text_chunks = [x.strip().replace(':','').replace('\\n', '') for x in value]\n",
    "        for i, x in enumerate(text_chunks):\n",
    "            if 'MEDICATION' in x or 'SOCIAL HISTORY' in x or 'FAMILY HISTORY' in x:\n",
    "                text_chunks[i] = ' '\n",
    "                try:\n",
    "                    text_chunks[i + 1] = ' '\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        text_series.iloc[row_num] = ' '.join(text_chunks)\n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Convert to lowercase \n",
    "    text_series = text_series.str.lower()\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    # Replace plurals, endings with ing, endings with ed, endings with ly\n",
    "#     text_series = text_series.str.replace('s(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ing(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ed(?=\\s)', ' ', regex=True)\n",
    "#     text_series = text_series.str.replace('ly(?=\\s)', ' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "# Update Text Column -----\n",
    "filtered_df.loc[:, 'TEXT'] = clean_data(filtered_df['TEXT']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-removal",
   "metadata": {},
   "source": [
    "# Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_df(filtered_df, percentile):\n",
    "    \n",
    "    # Check counts\n",
    "    df_cts = filtered_df['CPT_CD'].value_counts()\n",
    "    record_ct = round(np.percentile(df_cts, percentile))\n",
    "    print('New Balanced Record Count per CPT: {}'.format(record_ct))\n",
    "    \n",
    "    # Create a list of CPT values\n",
    "    df = list(df_cts.index.values)\n",
    "\n",
    "    # Resample\n",
    "    minority_df = []\n",
    "    for i in df:\n",
    "        test_resampled = resample(filtered_df[filtered_df['CPT_CD'] == i], replace=True, n_samples=record_ct, random_state=123)\n",
    "        minority_df.append(test_resampled)\n",
    "    \n",
    "    # Create final dataframe\n",
    "    new_df = pd.concat(minority_df)\n",
    "    new_df['CPT_CD'] = new_df['CPT_CD']\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "filtered_df_prelim = oversample_df(filtered_df, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the balanced data to the final df is satisfied with record count\n",
    "filtered_df = filtered_df_prelim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-steering",
   "metadata": {},
   "source": [
    "# Check for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(filtered_df['CPT_CD'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-mixer",
   "metadata": {},
   "source": [
    "# Label Encode the Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cooked-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "filtered_df['CPT_CD'] = le.fit_transform(filtered_df['CPT_CD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-strike",
   "metadata": {},
   "source": [
    "# Check the Counts for Each Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['SECTIONHEADER'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "double-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_dict = {} \n",
    "\n",
    "def split_stratify_df(df):\n",
    "    \n",
    "    for i in set(df['SECTIONHEADER']):\n",
    "        df_x = df[df['SECTIONHEADER'] == i]['TEXT'].values\n",
    "        df_y = df[df['SECTIONHEADER'] == i]['CPT_CD']\n",
    "        tt_dict['X_train_' + i], tt_dict['X_test_' + i], tt_dict['y_train_' + i], tt_dict['y_test_' + i], \\\n",
    "        tt_dict['index_train_' + i], tt_dict['index_test_' + i] = \\\n",
    "        train_test_split(df_x, df_y, range(len(df_y)), test_size = .1, random_state = 42, shuffle=True)\n",
    "\n",
    "split_stratify_df(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "pharmaceutical-cooling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Evaluation and management',\n",
       " 'Radiology',\n",
       " 'Pathology and laboratory',\n",
       " 'Medicine',\n",
       " 'Emerging technology',\n",
       " 'Surgery',\n",
       " 'Anesthesia']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print sections\n",
    "list(set(filtered_df['SECTIONHEADER']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected section:  Radiology\n"
     ]
    }
   ],
   "source": [
    "# Define stop words\n",
    "my_stop_words = list(set(stopwords.words('english'))) \\\n",
    "                + ['admission', 'date', 'sex'] \\\n",
    "                + ['needed', 'every', 'seen', 'weeks', 'please', 'ml', 'unit', 'small', 'year', 'old', 'cm', 'non', 'mm', 'however']\n",
    "                # Got the above from my top 100 most predictive words that I wanted to remove\n",
    "\n",
    "def vectorize_df(train_test_dict, section):\n",
    "    \n",
    "    # Import TfidfVectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words)\n",
    "\n",
    "    # Transform the training data\n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(train_test_dict['X_train_' + section])\n",
    "\n",
    "    # Transform the test data\n",
    "    tfidf_test = tfidf_vectorizer.transform(train_test_dict['X_test_' + section])\n",
    "    \n",
    "    # Add results to dictionary\n",
    "    vectorized_words = {}\n",
    "    vectorized_words['tfidf_train'] = tfidf_train\n",
    "    vectorized_words['tfidf_test'] = tfidf_test\n",
    "    \n",
    "    return vectorized_words, tfidf_vectorizer\n",
    "\n",
    "# Select a section\n",
    "section = list(set(filtered_df['SECTIONHEADER']))[1] \n",
    "print('Selected section: ', section)\n",
    "\n",
    "vectorized_words, tfidf_vectorizer = vectorize_df(tt_dict, section)                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-grenada",
   "metadata": {},
   "source": [
    "# Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cultural-india",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936544696618805\n"
     ]
    }
   ],
   "source": [
    "def run_clf(vectorized_words, train_test_dict, section):\n",
    "\n",
    "    # Use Naive Bayes model\n",
    "    nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "    # Fit and check accuracy\n",
    "    nb_classifier.fit(vectorized_words['tfidf_train'], train_test_dict['y_train_' + section])\n",
    "    pred = nb_classifier.predict(vectorized_words['tfidf_test'])\n",
    "    \n",
    "    print(metrics.accuracy_score(train_test_dict['y_test_' + section], pred))\n",
    "    \n",
    "    return pred, nb_classifier\n",
    "    \n",
    "pred, nb_classifier = run_clf(vectorized_words, tt_dict, section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-detective",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "forty-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936544696618805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nChecks on counts of CPT code per encounter\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 200\\nCategory/Categories: Discharge Summary\\n\\nNo constraints on CPT codes per encounter: 0.5082697201017812\\nOne CPT code per encounter: 0.5510543263737405\\nThree CPT codes or less per encounter: 0.52065226388544\\n\\nResults: Looks like the accuracy is improved quite a bit when using just one CPT per encounter. The downside is less data\\n-----------------------------------------\\n\\n#####\\n\\nChecks on using all notes vs. only the discharge summary section\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 200\\nNumber of CPT's per record: unrestricted\\n\\nDischarge Summary: .50\\nAll notes: 0.48813608819449517\\n\\nResults: Using all notes lead to a decreased accuracy\\n-----------------------------------------\\n\\n#####\\n\\nUsing ['Consult','Discharge summary','General', 'Nursing', 'Nursing/other', 'Physician ','Rehab Services','Respiratory ']\\ncategories instead of just discharge summary\\n-----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 200\\nNumber of CPT's per record: 1\\n\\nDischarge Summary: .799\\nSelected Categories: 0.7163814180929096\\n\\nResults: Using more notes decreased the score\\n----------------------------------------\\n\\n##### \\n\\nWhat effect does decreasing the note sample size have on accuracy?\\n----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: 50\\nNumber of CPT's per record: 1\\n\\nDischarge Summary w/200 notes per CPT: .799\\nDischarge Summary w/50 notes per CPT: 0.7609038360483448\\nDischarge Summary w/40 notes per CPT: 0.7788505747126436\\nDischarge Summary w/20 notes per CPT: 0.8029423151374371\\nDischarge Summary w/10 notes per CPT: 0.8027961736571008\\nDischarge Summary - no threshold for notes per CPT: 0.9673274394596673\\n\\nResults: It looks like a note restriction is unnecessary\\n----------------------------------------\\n\\n#####\\n\\nDoes balancing the data improve the model's accuracy?\\n----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: no-restriction\\nNumber of CPT's per record: 1\\n\\nAccuracy without balancing: 0.344578313253012\\nAccuracy with balancing: 0.9673274394596673\\n\\nResults: It definitely helps\\n\\n#####\\n\\nDoes using label encoding affect accuracy?\\n----------------------------------------\\nTest size: .1\\nRandom Number: 42\\n# of records per CPT: no-restriction\\nNumber of CPT's per record: 1\\n\\nAccuracy without labelencoding: 0.9673274394596673\\nAccuracy with labelencoding: 0.9673274394596673\\n\\nResults: No, but it is still a good idea since they are deprecating the ability to have strings as predictors\\n\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy\n",
    "print(metrics.accuracy_score(tt_dict['y_test_' + section], pred))\n",
    "\n",
    "\"\"\"\n",
    "Checks on counts of CPT code per encounter\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 200\n",
    "Category/Categories: Discharge Summary\n",
    "\n",
    "No constraints on CPT codes per encounter: 0.5082697201017812\n",
    "One CPT code per encounter: 0.5510543263737405\n",
    "Three CPT codes or less per encounter: 0.52065226388544\n",
    "\n",
    "Results: Looks like the accuracy is improved quite a bit when using just one CPT per encounter. The downside is less data\n",
    "-----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Checks on using all notes vs. only the discharge summary section\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 200\n",
    "Number of CPT's per record: unrestricted\n",
    "\n",
    "Discharge Summary: .50\n",
    "All notes: 0.48813608819449517\n",
    "\n",
    "Results: Using all notes lead to a decreased accuracy\n",
    "-----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Using ['Consult','Discharge summary','General', 'Nursing', 'Nursing/other', 'Physician ','Rehab Services','Respiratory ']\n",
    "categories instead of just discharge summary\n",
    "-----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 200\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Discharge Summary: .799\n",
    "Selected Categories: 0.7163814180929096\n",
    "\n",
    "Results: Using more notes decreased the score\n",
    "----------------------------------------\n",
    "\n",
    "##### \n",
    "\n",
    "What effect does decreasing the note sample size have on accuracy?\n",
    "----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: 50\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Discharge Summary w/200 notes per CPT: .799\n",
    "Discharge Summary w/50 notes per CPT: 0.7609038360483448\n",
    "Discharge Summary w/40 notes per CPT: 0.7788505747126436\n",
    "Discharge Summary w/20 notes per CPT: 0.8029423151374371\n",
    "Discharge Summary w/10 notes per CPT: 0.8027961736571008\n",
    "Discharge Summary - no threshold for notes per CPT: 0.9673274394596673\n",
    "\n",
    "Results: It looks like a note restriction is unnecessary\n",
    "----------------------------------------\n",
    "\n",
    "#####\n",
    "\n",
    "Does balancing the data improve the model's accuracy?\n",
    "----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: no-restriction\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Accuracy without balancing: 0.344578313253012\n",
    "Accuracy with balancing: 0.9673274394596673\n",
    "\n",
    "Results: It definitely helps\n",
    "\n",
    "#####\n",
    "\n",
    "Does using label encoding affect accuracy?\n",
    "----------------------------------------\n",
    "Test size: .1\n",
    "Random Number: 42\n",
    "# of records per CPT: no-restriction\n",
    "Number of CPT's per record: 1\n",
    "\n",
    "Accuracy without labelencoding: 0.9673274394596673\n",
    "Accuracy with labelencoding: 0.9673274394596673\n",
    "\n",
    "Results: No, but it is still a good idea since they are deprecating the ability to have strings as predictors\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "useful-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       75710       0.89      0.88      0.88      1095\n",
      "       75940       0.93      0.89      0.91      1058\n",
      "       75952       0.92      1.00      0.96      1100\n",
      "       75960       0.81      0.82      0.82      1042\n",
      "       75989       1.00      1.00      1.00      1073\n",
      "       76604       0.99      1.00      0.99      1088\n",
      "       76937       0.90      0.84      0.87      1073\n",
      "       76942       0.95      0.93      0.94      1119\n",
      "       77001       1.00      1.00      1.00      1056\n",
      "       77071       0.97      0.99      0.98      1091\n",
      "\n",
      "    accuracy                           0.94     10795\n",
      "   macro avg       0.94      0.94      0.94     10795\n",
      "weighted avg       0.94      0.94      0.94     10795\n",
      "\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       75710       0.89      0.88      0.88      9700\n",
      "       75940       0.91      0.88      0.90      9737\n",
      "       75952       0.92      1.00      0.96      9695\n",
      "       75960       0.81      0.82      0.82      9753\n",
      "       75989       0.99      1.00      1.00      9722\n",
      "       76604       0.99      1.00      0.99      9707\n",
      "       76937       0.90      0.84      0.87      9722\n",
      "       76942       0.95      0.93      0.94      9676\n",
      "       77001       1.00      1.00      1.00      9739\n",
      "       77071       0.97      0.99      0.98      9704\n",
      "\n",
      "    accuracy                           0.93     97155\n",
      "   macro avg       0.93      0.93      0.93     97155\n",
      "weighted avg       0.93      0.93      0.93     97155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "print('Test')\n",
    "class_labels = nb_classifier.classes_\n",
    "print(classification_report(tt_dict['y_test_' + section], pred))\n",
    "\n",
    "print('Training')\n",
    "pred_x = nb_classifier.predict(vectorized_words['tfidf_train'])\n",
    "print(classification_report(tt_dict['y_train_' + section], pred_x))\n",
    "\n",
    "# Counts by number of CPT values in test\n",
    "# print(tt_dict['y_test_' + section].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-mining",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "similar-senator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76937 39.24%\n",
      "[0.081577   0.07145138 0.00189492 0.01552887 0.03092027 0.11255151\n",
      " 0.39237473 0.27588978 0.01120923 0.0066023 ]\n"
     ]
    }
   ],
   "source": [
    "def predict_cpt(text):\n",
    "    input_text_clean = clean_data(pd.Series(text))\n",
    "    tfidf_input_test = tfidf_vectorizer.transform(input_text_clean)\n",
    "    print(nb_classifier.predict(tfidf_input_test)[0], str(round(max(nb_classifier.predict_proba(tfidf_input_test)[0]) * 100,2)) + '%')\n",
    "    print(nb_classifier.predict_proba(tfidf_input_test)[0])\n",
    "          \n",
    "text_cpt = 'Report this code as an add–on code to the primary procedure code, such as central venous access devices (CVAD) placement, replacement, or removal, including accessing the vessel, manipulating the catheter, contrast injection via the access site or catheter, and venography–related radiologic supervision and interpretation and image documentation of final catheter position. The code cannot be reported as a standalone code.'\n",
    "predict_cpt(text_cpt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
