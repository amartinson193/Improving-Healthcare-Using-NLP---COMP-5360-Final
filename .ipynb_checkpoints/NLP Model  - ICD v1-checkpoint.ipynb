{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "built-romance",
   "metadata": {},
   "source": [
    "# Changes from CPT v9\n",
    "* Just using ICD codes\n",
    "* 96.1286% accuracy\n",
    "* Removing bottom least predictive words reduced model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-alabama",
   "metadata": {},
   "source": [
    "\n",
    "# Import the MIMIC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-smile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "dataset_dictionary = {}\n",
    "\n",
    "for file_path in glob.glob('.\\\\Data\\\\MIMIC Files\\*'):\n",
    "    file_name = file_path.split('\\\\')[3].split('.')[0]\n",
    "    with gzip.open(file_path, mode='r') as file:\n",
    "        dataset_dictionary[file_name] = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-desert",
   "metadata": {},
   "source": [
    "# Join the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grateful-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset to join together -----\n",
    "\n",
    "# Create note_events table -----\n",
    "\n",
    "def join_notes_and_icd(dataset_dictionary):\n",
    "    # Combine text for each subject and encounter\n",
    "    note_events_base = dataset_dictionary['NOTEEVENTS'][dataset_dictionary['NOTEEVENTS'].loc[:,'CATEGORY'] == 'Discharge summary']\n",
    "    note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "\n",
    "    # Create ICD table -----\n",
    "    icd_df = dataset_dictionary['DIAGNOSES_ICD']\n",
    "    icd_df = icd_df[icd_df['SEQ_NUM'] == 1]\n",
    "    icd_events_base = icd_df.loc[:, ['SUBJECT_ID','HADM_ID', 'ICD9_CODE']]\n",
    "    icd_events = icd_events_base.drop_duplicates()\n",
    "\n",
    "    # Join the datasets -----\n",
    "\n",
    "    notes_combined = note_events.merge(icd_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "    # print(note_cpt.shape, note_events.shape, cpt_events.shape) # (223,150, 4) (52,726, 3) (227,510, 3)\n",
    "    \n",
    "    return notes_combined\n",
    "\n",
    "def join_notes_and_cpt(dataset_dictionary):\n",
    "    # Combine text for each subject and encounter\n",
    "    note_events_base = dataset_dictionary['NOTEEVENTS'][dataset_dictionary['NOTEEVENTS'].loc[:,'CATEGORY'] == 'Discharge summary']\n",
    "    note_events = note_events_base.groupby(['SUBJECT_ID', 'HADM_ID'], as_index=False)['TEXT'].agg(sum)\n",
    "\n",
    "    # Create CPT table -----\n",
    "\n",
    "    cpt_events_base = dataset_dictionary['CPTEVENTS'].loc[:, ['SUBJECT_ID','HADM_ID', 'CPT_CD']]\n",
    "    cpt_events = cpt_events_base.drop_duplicates()\n",
    "\n",
    "    # Join the datasets -----\n",
    "\n",
    "    notes_combined = note_events.merge(cpt_events, on = ['SUBJECT_ID','HADM_ID'])\n",
    "    # print(note_cpt.shape, note_events.shape, cpt_events.shape) # (223,150, 4) (52,726, 3) (227,510, 3)\n",
    "    \n",
    "    return notes_combined\n",
    "\n",
    "icd_df = join_notes_and_icd(dataset_dictionary)\n",
    "# dataset_dictionary['DIAGNOSES_ICD']['SEQ_NUM']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-steering",
   "metadata": {},
   "source": [
    "# Check for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "altered-lucas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# icd_df['ICD9_CODE'].astype(str)\n",
    "x = icd_df['ICD9_CODE'].astype(str)\n",
    "\n",
    "plt.hist(x.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-norman",
   "metadata": {},
   "source": [
    "# Filter to top 3 diagnosis codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demonstrated-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_df['ICD9_CODE'].astype(str).value_counts(ascending=False)\n",
    "icd_df_3 = icd_df[icd_df['ICD9_CODE'].isin(['0389', '41071', 'V3001'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-september",
   "metadata": {},
   "source": [
    "# Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unable-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        admission date        discharge date     date ...\n",
       "13       admission date                 discharge date ...\n",
       "19       admission date                 discharge date ...\n",
       "25       admission date        discharge date      serv...\n",
       "31       admission date        discharge date     date ...\n",
       "                               ...                        \n",
       "52597    admission date                 discharge date ...\n",
       "52638    admission date                 discharge date ...\n",
       "52644    admission date                 discharge date ...\n",
       "52695    admission date                 discharge date ...\n",
       "52717    admission date                 discharge date ...\n",
       "Name: TEXT, Length: 5085, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def clean_data(text_series):\n",
    "    \n",
    "    # Replace \\n \n",
    "    text_series = text_series.str.replace('\\\\n',' ', regex=True)    \n",
    "\n",
    "    # Remove dates and locations\n",
    "    text_series = text_series.str.replace('\\[\\*\\*(.*?)\\*\\*\\]', ' ', regex=True)\n",
    "    \n",
    "    # Remove topics\n",
    "    data = text_series.str.split('([A-Z\\s]+:)')\n",
    "    for row_num, value in enumerate(data):\n",
    "        text_chunks = [x.strip().replace(':','').replace('\\n', '') for x in value]\n",
    "        for i, x in enumerate(text_chunks):\n",
    "            if 'MEDICATION' in x or 'SOCIAL HISTORY' in x or 'FAMILY HISTORY' in x:\n",
    "                text_chunks[i] = ' '\n",
    "                try:\n",
    "                    text_chunks[i + 1] = ' '\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        text_series.iloc[row_num] = ' '.join(text_chunks)\n",
    "    \n",
    "    # Replace punctuation\n",
    "    text_series = text_series.str.replace('[' + string.punctuation + ']', ' ', regex=True)\n",
    "    \n",
    "    # Convert to lowercase \n",
    "    text_series = text_series.str.lower()\n",
    "    \n",
    "    # Remove all digits\n",
    "    text_series = text_series.str.replace('\\d',' ', regex=True)\n",
    "    \n",
    "    return text_series\n",
    "\n",
    "\n",
    "icd_df_3_clean = clean_data(icd_df_3['TEXT'])\n",
    "icd_df_3_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-measure",
   "metadata": {},
   "source": [
    "# Update text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "behind-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "icd_df_3.loc[:, 'TEXT'] = icd_df_3_clean.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-bracket",
   "metadata": {},
   "source": [
    "# Shuffle the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "surprised-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_df_3 = icd_df_3.sample(n = len(icd_df_3), random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-devil",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extensive-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages -----\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "my_stop_words = list(set(stopwords.words('english'))) \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the data -----\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(icd_df_3['TEXT'].values, icd_df_3['ICD9_CODE'].astype(str), test_size = .33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-comment",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "determined-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data -----\n",
    "\n",
    "# Import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words, min_df = 3, max_df = .7, sublinear_tf=True)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-grenada",
   "metadata": {},
   "source": [
    "# Run Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cultural-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes model -----\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "# Fit and check accuracy\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-decrease",
   "metadata": {},
   "source": [
    "# Tune NB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sexual-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.421076621541547\n",
      "0.1\n",
      "0.421076621541547\n",
      "0.2\n",
      "0.421076621541547\n",
      "0.30000000000000004\n",
      "0.421076621541547\n",
      "0.4\n",
      "0.421076621541547\n",
      "0.5\n",
      "0.421076621541547\n",
      "0.6000000000000001\n",
      "0.421076621541547\n",
      "0.7000000000000001\n",
      "0.421076621541547\n",
      "0.8\n",
      "0.421076621541547\n",
      "0.9\n",
      "0.421076621541547\n",
      "1.0\n",
      "0.421076621541547\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def hyperparam_tuning(tfidf_train, y_train, tfidf_test, y_test, nb_classifier):\n",
    "    for i in np.arange(0,1.1,.1):\n",
    "        nb_classifier = MultinomialNB()\n",
    "        nb_classifier.fit(tfidf_train, y_train)\n",
    "        pred = nb_classifier.predict(tfidf_test)\n",
    "        print(i)\n",
    "        print(metrics.accuracy_score(y_test, pred))\n",
    "\n",
    "hyperparam_tuning(tfidf_train, y_train, tfidf_test, y_test, nb_classifier)  \n",
    "\n",
    "# Looks like .6-.7 are the best alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-guess",
   "metadata": {},
   "source": [
    "# Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "under-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_logist = LogisticRegression(C=.001, random_state = 42, multi_class = 'multinomial', penalty='l2')\n",
    "clf_logist.fit(tfidf_train, y_train)\n",
    "logist_pred = clf_logist.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-ultimate",
   "metadata": {},
   "source": [
    "# Looking at Feature Names and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "decent-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0389 0 0.0022 po\n",
      "0389 1 0.0022 pm\n",
      "0389 2 0.002 daily\n",
      "0389 3 0.002 pt\n",
      "0389 4 0.0018 ct\n",
      "0389 5 0.0016 pneumonia\n",
      "0389 6 0.0016 pain\n",
      "0389 7 0.0016 urine\n",
      "0389 8 0.0016 wbc\n",
      "0389 9 0.0016 neg\n",
      "0389 10 0.0015 likely\n",
      "0389 11 0.0015 ed\n",
      "0389 12 0.0015 hypotension\n",
      "0389 13 0.0015 lactate\n",
      "0389 14 0.0014 hct\n",
      "0389 15 0.0014 failure\n",
      "0389 16 0.0014 instructions\n",
      "0389 17 0.0013 rbc\n",
      "0389 18 0.0013 needed\n",
      "0389 19 0.0013 cxr\n",
      "0389 20 0.0013 every\n",
      "0389 21 0.0013 plt\n",
      "0389 22 0.0013 sepsis\n",
      "0389 23 0.0013 vancomycin\n",
      "0389 24 0.0013 acute\n",
      "0389 25 0.0013 iv\n",
      "0389 26 0.0013 prn\n",
      "0389 27 0.0013 bp\n",
      "0389 28 0.0013 renal\n",
      "0389 29 0.0013 line\n",
      "0389 30 0.0013 glucose\n",
      "0389 31 0.0013 infection\n",
      "0389 32 0.0013 hr\n",
      "0389 33 0.0012 abdominal\n",
      "0389 34 0.0012 ml\n",
      "0389 35 0.0012 times\n",
      "0389 36 0.0012 days\n",
      "0389 37 0.0012 status\n",
      "0389 38 0.0012 hgb\n",
      "0389 39 0.0012 continued\n",
      "0389 40 0.0012 mcv\n",
      "0389 41 0.0012 rdw\n",
      "0389 42 0.0012 mch\n",
      "0389 43 0.0012 mchc\n",
      "0389 44 0.0012 creat\n",
      "0389 45 0.0012 please\n",
      "0389 46 0.0012 expired\n",
      "0389 47 0.0012 fluid\n",
      "0389 48 0.0012 edema\n",
      "0389 49 0.0011 icu\n",
      "0389 50 0.0011 lower\n",
      "0389 51 0.0011 tube\n",
      "0389 52 0.0011 inr\n",
      "0389 53 0.0011 seen\n",
      "0389 54 0.0011 allergies\n",
      "0389 55 0.0011 evidence\n",
      "0389 56 0.0011 flagyl\n",
      "0389 57 0.0011 improved\n",
      "0389 58 0.0011 per\n",
      "0389 59 0.0011 micu\n",
      "0389 60 0.0011 fever\n",
      "0389 61 0.0011 baseline\n",
      "0389 62 0.0011 due\n",
      "0389 63 0.0011 pulmonary\n",
      "0389 64 0.0011 low\n",
      "0389 65 0.0011 calcium\n",
      "0389 66 0.0011 secondary\n",
      "0389 67 0.0011 mental\n",
      "0389 68 0.0011 found\n",
      "0389 69 0.0011 placed\n",
      "0389 70 0.0011 na\n",
      "0389 71 0.0011 antibiotics\n",
      "0389 72 0.0011 bid\n",
      "0389 73 0.001 surgical\n",
      "0389 74 0.001 tid\n",
      "0389 75 0.001 non\n",
      "0389 76 0.001 showed\n",
      "0389 77 0.001 pleural\n",
      "0389 78 0.001 release\n",
      "0389 79 0.001 noted\n",
      "0389 80 0.001 medicine\n",
      "0389 81 0.001 mcg\n",
      "0389 82 0.001 however\n",
      "0389 83 0.001 setting\n",
      "0389 84 0.001 chronic\n",
      "0389 85 0.001 floor\n",
      "0389 86 0.001 initially\n",
      "0389 87 0.001 intubated\n",
      "0389 88 0.001 zosyn\n",
      "0389 89 0.001 placement\n",
      "0389 90 0.001 alt\n",
      "0389 91 0.001 small\n",
      "0389 92 0.001 ast\n",
      "0389 93 0.001 abd\n",
      "0389 94 0.001 phos\n",
      "0389 95 0.001 treated\n",
      "0389 96 0.001 ck\n",
      "0389 97 0.001 cl\n",
      "0389 98 0.001 multiple\n",
      "0389 99 0.001 elevated\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Bottom 100 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0389 0 0.0 wise\n",
      "0389 1 0.0 concise\n",
      "0389 2 0.0 interpreted\n",
      "0389 3 0.0 dad\n",
      "0389 4 0.0 supports\n",
      "0389 5 0.0 mechanic\n",
      "0389 6 0.0 basically\n",
      "0389 7 0.0 persisting\n",
      "0389 8 0.0 haziness\n",
      "0389 9 0.0 infiltrated\n",
      "0389 10 0.0 totally\n",
      "0389 11 0.0 drs\n",
      "0389 12 0.0 transit\n",
      "0389 13 0.0 radiates\n",
      "0389 14 0.0 character\n",
      "0389 15 0.0 pseudo\n",
      "0389 16 0.0 ideal\n",
      "0389 17 0.0 exhibited\n",
      "0389 18 0.0 accompanying\n",
      "0389 19 0.0 fo\n",
      "0389 20 0.0 kids\n",
      "0389 21 0.0 exhibit\n",
      "0389 22 0.0 big\n",
      "0389 23 0.0 occassional\n",
      "0389 24 0.0 suffers\n",
      "0389 25 0.0 separation\n",
      "0389 26 0.0 fluoroscopy\n",
      "0389 27 0.0 precipitated\n",
      "0389 28 0.0 thrombotic\n",
      "0389 29 0.0 relatives\n",
      "0389 30 0.0 arrested\n",
      "0389 31 0.0 interview\n",
      "0389 32 0.0 raynaud\n",
      "0389 33 0.0 pao\n",
      "0389 34 0.0 prednisolone\n",
      "0389 35 0.0 scanning\n",
      "0389 36 0.0 ectopic\n",
      "0389 37 0.0 nondisplaced\n",
      "0389 38 0.0 upwards\n",
      "0389 39 0.0 terminated\n",
      "0389 40 0.0 fibroid\n",
      "0389 41 0.0 polio\n",
      "0389 42 0.0 gallop\n",
      "0389 43 0.0 hair\n",
      "0389 44 0.0 separated\n",
      "0389 45 0.0 clotted\n",
      "0389 46 0.0 preferred\n",
      "0389 47 0.0 deceleration\n",
      "0389 48 0.0 maculopapular\n",
      "0389 49 0.0 costal\n",
      "0389 50 0.0 induction\n",
      "0389 51 0.0 crossed\n",
      "0389 52 0.0 paper\n",
      "0389 53 0.0 valves\n",
      "0389 54 0.0 polycythemia\n",
      "0389 55 0.0 lie\n",
      "0389 56 0.0 saphenous\n",
      "0389 57 0.0 gradients\n",
      "0389 58 0.0 bank\n",
      "0389 59 0.0 perspective\n",
      "0389 60 0.0 preformed\n",
      "0389 61 0.0 shingles\n",
      "0389 62 0.0 obscuring\n",
      "0389 63 0.0 hopefully\n",
      "0389 64 0.0 association\n",
      "0389 65 0.0 performing\n",
      "0389 66 0.0 genitourinary\n",
      "0389 67 0.0 car\n",
      "0389 68 0.0 electrophysiology\n",
      "0389 69 0.0 hematologist\n",
      "0389 70 0.0 arrhythmias\n",
      "0389 71 0.0 measurement\n",
      "0389 72 0.0 restrictions\n",
      "0389 73 0.0001 lowered\n",
      "0389 74 0.0001 thorough\n",
      "0389 75 0.0001 resuscitative\n",
      "0389 76 0.0001 variant\n",
      "0389 77 0.0001 manipulation\n",
      "0389 78 0.0001 table\n",
      "0389 79 0.0001 aneurysms\n",
      "0389 80 0.0001 congenital\n",
      "0389 81 0.0001 passage\n",
      "0389 82 0.0001 hematocrits\n",
      "0389 83 0.0001 cauterized\n",
      "0389 84 0.0001 indomethacin\n",
      "0389 85 0.0001 ones\n",
      "0389 86 0.0001 vigorous\n",
      "0389 87 0.0001 desaturations\n",
      "0389 88 0.0001 opinion\n",
      "0389 89 0.0001 guidelines\n",
      "0389 90 0.0001 nuchal\n",
      "0389 91 0.0001 difference\n",
      "0389 92 0.0001 gastroenterologist\n",
      "0389 93 0.0001 choice\n",
      "0389 94 0.0001 hormone\n",
      "0389 95 0.0001 oophorectomy\n",
      "0389 96 0.0001 effectively\n",
      "0389 97 0.0001 resonance\n",
      "0389 98 0.0001 till\n",
      "0389 99 0.0001 therapist\n",
      "Top 100 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "41071 0 0.0031 coronary\n",
      "41071 1 0.0029 artery\n",
      "41071 2 0.0026 cardiac\n",
      "41071 3 0.0025 catheterization\n",
      "41071 4 0.0023 pain\n",
      "41071 5 0.0023 po\n",
      "41071 6 0.0023 daily\n",
      "41071 7 0.0021 ventricular\n",
      "41071 8 0.0021 aortic\n",
      "41071 9 0.002 bypass\n",
      "41071 10 0.0019 release\n",
      "41071 11 0.0019 pt\n",
      "41071 12 0.0019 stenosis\n",
      "41071 13 0.0019 valve\n",
      "41071 14 0.0018 ck\n",
      "41071 15 0.0018 mitral\n",
      "41071 16 0.0018 pm\n",
      "41071 17 0.0017 post\n",
      "41071 18 0.0017 aspirin\n",
      "41071 19 0.0017 times\n",
      "41071 20 0.0017 dr\n",
      "41071 21 0.0016 transferred\n",
      "41071 22 0.0016 st\n",
      "41071 23 0.0016 vessel\n",
      "41071 24 0.0016 please\n",
      "41071 25 0.0016 regurgitation\n",
      "41071 26 0.0016 descending\n",
      "41071 27 0.0016 delayed\n",
      "41071 28 0.0016 surgery\n",
      "41071 29 0.0016 systolic\n",
      "41071 30 0.0016 hypertension\n",
      "41071 31 0.0015 postoperative\n",
      "41071 32 0.0015 infarction\n",
      "41071 33 0.0015 wall\n",
      "41071 34 0.0015 seen\n",
      "41071 35 0.0014 heparin\n",
      "41071 36 0.0014 revealed\n",
      "41071 37 0.0014 leaflets\n",
      "41071 38 0.0014 mild\n",
      "41071 39 0.0014 follow\n",
      "41071 40 0.0014 showed\n",
      "41071 41 0.0014 two\n",
      "41071 42 0.0014 pressure\n",
      "41071 43 0.0014 pulmonary\n",
      "41071 44 0.0014 continued\n",
      "41071 45 0.0014 allergies\n",
      "41071 46 0.0014 weeks\n",
      "41071 47 0.0014 ct\n",
      "41071 48 0.0014 call\n",
      "41071 49 0.0014 atrial\n",
      "41071 50 0.0014 instructions\n",
      "41071 51 0.0014 mildly\n",
      "41071 52 0.0013 mid\n",
      "41071 53 0.0013 vein\n",
      "41071 54 0.0013 stent\n",
      "41071 55 0.0013 edema\n",
      "41071 56 0.0013 three\n",
      "41071 57 0.0013 distal\n",
      "41071 58 0.0013 saphenous\n",
      "41071 59 0.0013 function\n",
      "41071 60 0.0013 sinus\n",
      "41071 61 0.0013 aorta\n",
      "41071 62 0.0013 underwent\n",
      "41071 63 0.0013 hr\n",
      "41071 64 0.0013 size\n",
      "41071 65 0.0013 acute\n",
      "41071 66 0.0013 rhythm\n",
      "41071 67 0.0013 status\n",
      "41071 68 0.0012 bid\n",
      "41071 69 0.0012 hct\n",
      "41071 70 0.0012 diabetes\n",
      "41071 71 0.0012 proximal\n",
      "41071 72 0.0012 every\n",
      "41071 73 0.0012 glucose\n",
      "41071 74 0.0012 severe\n",
      "41071 75 0.0012 anterior\n",
      "41071 76 0.0012 inr\n",
      "41071 77 0.0012 sustained\n",
      "41071 78 0.0012 free\n",
      "41071 79 0.0012 plt\n",
      "41071 80 0.0012 procedure\n",
      "41071 81 0.0012 thickened\n",
      "41071 82 0.0011 found\n",
      "41071 83 0.0011 wbc\n",
      "41071 84 0.0011 drip\n",
      "41071 85 0.0011 lesion\n",
      "41071 86 0.0011 lasix\n",
      "41071 87 0.0011 moderate\n",
      "41071 88 0.0011 non\n",
      "41071 89 0.0011 days\n",
      "41071 90 0.0011 ekg\n",
      "41071 91 0.0011 needed\n",
      "41071 92 0.0011 shortness\n",
      "41071 93 0.0011 elevated\n",
      "41071 94 0.0011 without\n",
      "41071 95 0.0011 creatinine\n",
      "41071 96 0.0011 inferior\n",
      "41071 97 0.0011 ejection\n",
      "41071 98 0.0011 surgical\n",
      "41071 99 0.0011 mm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Bottom 100 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "41071 0 0.0 identify\n",
      "41071 1 0.0 fourteen\n",
      "41071 2 0.0 enema\n",
      "41071 3 0.0 nares\n",
      "41071 4 0.0 appendix\n",
      "41071 5 0.0 reticular\n",
      "41071 6 0.0 producing\n",
      "41071 7 0.0 reassess\n",
      "41071 8 0.0 establish\n",
      "41071 9 0.0 conditions\n",
      "41071 10 0.0 anatomic\n",
      "41071 11 0.0 vbg\n",
      "41071 12 0.0 pubic\n",
      "41071 13 0.0 influenza\n",
      "41071 14 0.0 obviously\n",
      "41071 15 0.0 hypothermia\n",
      "41071 16 0.0 reconsulted\n",
      "41071 17 0.0 investigation\n",
      "41071 18 0.0 performance\n",
      "41071 19 0.0 margins\n",
      "41071 20 0.0 crystalloid\n",
      "41071 21 0.0 lithium\n",
      "41071 22 0.0 antigen\n",
      "41071 23 0.0 girth\n",
      "41071 24 0.0 meetings\n",
      "41071 25 0.0 resected\n",
      "41071 26 0.0 hypercarbia\n",
      "41071 27 0.0 types\n",
      "41071 28 0.0 undetectable\n",
      "41071 29 0.0 uric\n",
      "41071 30 0.0 barrier\n",
      "41071 31 0.0 placements\n",
      "41071 32 0.0 pro\n",
      "41071 33 0.0 tracheomalacia\n",
      "41071 34 0.0 pseudo\n",
      "41071 35 0.0 attempting\n",
      "41071 36 0.0 ob\n",
      "41071 37 0.0 citrobacter\n",
      "41071 38 0.0 mortality\n",
      "41071 39 0.0 partly\n",
      "41071 40 0.0 undetermined\n",
      "41071 41 0.0 chance\n",
      "41071 42 0.0 punctate\n",
      "41071 43 0.0 utis\n",
      "41071 44 0.0 enhanced\n",
      "41071 45 0.0 orders\n",
      "41071 46 0.0 exceed\n",
      "41071 47 0.0 prepped\n",
      "41071 48 0.0 species\n",
      "41071 49 0.0 supports\n",
      "41071 50 0.0 bacitracin\n",
      "41071 51 0.0 hemorrhages\n",
      "41071 52 0.0 summer\n",
      "41071 53 0.0 switch\n",
      "41071 54 0.0 pancytopenia\n",
      "41071 55 0.0 vasopressors\n",
      "41071 56 0.0 ritalin\n",
      "41071 57 0.0 autoimmune\n",
      "41071 58 0.0 lymphedema\n",
      "41071 59 0.0 stays\n",
      "41071 60 0.0 attentive\n",
      "41071 61 0.0 ugi\n",
      "41071 62 0.0 visualize\n",
      "41071 63 0.0 correlated\n",
      "41071 64 0.0 dorsum\n",
      "41071 65 0.0 vented\n",
      "41071 66 0.0 shingles\n",
      "41071 67 0.0 regain\n",
      "41071 68 0.0 passage\n",
      "41071 69 0.0 conversations\n",
      "41071 70 0.0 stenotrophomonas\n",
      "41071 71 0.0 vasculitis\n",
      "41071 72 0.0 carried\n",
      "41071 73 0.0 drifted\n",
      "41071 74 0.0 jerks\n",
      "41071 75 0.0 behavior\n",
      "41071 76 0.0 timing\n",
      "41071 77 0.0 debris\n",
      "41071 78 0.0 profoundly\n",
      "41071 79 0.0 hyperactive\n",
      "41071 80 0.0 cord\n",
      "41071 81 0.0 sluggish\n",
      "41071 82 0.0 scanning\n",
      "41071 83 0.0 hemolytic\n",
      "41071 84 0.0 contained\n",
      "41071 85 0.0 im\n",
      "41071 86 0.0 intracardiac\n",
      "41071 87 0.0 incarcerated\n",
      "41071 88 0.0 benzos\n",
      "41071 89 0.0 urethra\n",
      "41071 90 0.0 tremors\n",
      "41071 91 0.0 serology\n",
      "41071 92 0.0 passes\n",
      "41071 93 0.0 guidelines\n",
      "41071 94 0.0 excoriations\n",
      "41071 95 0.0 facilitate\n",
      "41071 96 0.0 group\n",
      "41071 97 0.0 hyperventilation\n",
      "41071 98 0.0 sooner\n",
      "41071 99 0.0 locally\n",
      "Top 100 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "V3001 0 0.0059 life\n",
      "V3001 1 0.0042 age\n",
      "V3001 2 0.0037 respiratory\n",
      "V3001 3 0.0036 mother\n",
      "V3001 4 0.0036 hepatitis\n",
      "V3001 5 0.0035 weight\n",
      "V3001 6 0.0034 th\n",
      "V3001 7 0.0033 feeding\n",
      "V3001 8 0.0033 screening\n",
      "V3001 9 0.0033 breast\n",
      "V3001 10 0.0032 screen\n",
      "V3001 11 0.0031 weeks\n",
      "V3001 12 0.0031 kg\n",
      "V3001 13 0.0031 cardiovascular\n",
      "V3001 14 0.0031 section\n",
      "V3001 15 0.003 bilirubin\n",
      "V3001 16 0.003 electrolytes\n",
      "V3001 17 0.003 cm\n",
      "V3001 18 0.003 room\n",
      "V3001 19 0.0029 air\n",
      "V3001 20 0.0029 murmur\n",
      "V3001 21 0.0029 examination\n",
      "V3001 22 0.0029 head\n",
      "V3001 23 0.0029 feeds\n",
      "V3001 24 0.0029 grams\n",
      "V3001 25 0.0028 received\n",
      "V3001 26 0.0028 milk\n",
      "V3001 27 0.0027 intensive\n",
      "V3001 28 0.0027 length\n",
      "V3001 29 0.0027 recommended\n",
      "V3001 30 0.0027 apnea\n",
      "V3001 31 0.0027 influenza\n",
      "V3001 32 0.0026 positive\n",
      "V3001 33 0.0026 antibody\n",
      "V3001 34 0.0026 fluids\n",
      "V3001 35 0.0025 distress\n",
      "V3001 36 0.0025 hearing\n",
      "V3001 37 0.0025 nutrition\n",
      "V3001 38 0.0025 tone\n",
      "V3001 39 0.0024 months\n",
      "V3001 40 0.0024 medquist\n",
      "V3001 41 0.0024 job\n",
      "V3001 42 0.0024 dictated\n",
      "V3001 43 0.0024 surface\n",
      "V3001 44 0.0024 hematocrit\n",
      "V3001 45 0.0024 sepsis\n",
      "V3001 46 0.0024 cbc\n",
      "V3001 47 0.0024 rate\n",
      "V3001 48 0.0023 antigen\n",
      "V3001 49 0.0023 infectious\n",
      "V3001 50 0.0023 cc\n",
      "V3001 51 0.0023 car\n",
      "V3001 52 0.0023 state\n",
      "V3001 53 0.0023 per\n",
      "V3001 54 0.0023 ampicillin\n",
      "V3001 55 0.0022 remained\n",
      "V3001 56 0.0022 passed\n",
      "V3001 57 0.0022 oxygen\n",
      "V3001 58 0.0022 recommendations\n",
      "V3001 59 0.0022 performed\n",
      "V3001 60 0.0021 unit\n",
      "V3001 61 0.0021 unknown\n",
      "V3001 62 0.0021 minutes\n",
      "V3001 63 0.0021 parents\n",
      "V3001 64 0.0021 flat\n",
      "V3001 65 0.0021 sensory\n",
      "V3001 66 0.0021 hematology\n",
      "V3001 67 0.0021 intact\n",
      "V3001 68 0.0021 minute\n",
      "V3001 69 0.0021 sent\n",
      "V3001 70 0.002 count\n",
      "V3001 71 0.002 number\n",
      "V3001 72 0.002 culture\n",
      "V3001 73 0.002 first\n",
      "V3001 74 0.002 gentamicin\n",
      "V3001 75 0.002 group\n",
      "V3001 76 0.002 patent\n",
      "V3001 77 0.002 diagnoses\n",
      "V3001 78 0.0019 ears\n",
      "V3001 79 0.0019 sounds\n",
      "V3001 80 0.0019 following\n",
      "V3001 81 0.0019 noted\n",
      "V3001 82 0.0019 primary\n",
      "V3001 83 0.0019 limits\n",
      "V3001 84 0.0018 issues\n",
      "V3001 85 0.0018 considered\n",
      "V3001 86 0.0018 gastrointestinal\n",
      "V3001 87 0.0018 active\n",
      "V3001 88 0.0018 required\n",
      "V3001 89 0.0018 antibiotics\n",
      "V3001 90 0.0018 dr\n",
      "V3001 91 0.0018 cpap\n",
      "V3001 92 0.0018 nasal\n",
      "V3001 93 0.0018 ultrasound\n",
      "V3001 94 0.0018 initial\n",
      "V3001 95 0.0018 membranes\n",
      "V3001 96 0.0018 week\n",
      "V3001 97 0.0018 neurology\n",
      "V3001 98 0.0018 rule\n",
      "V3001 99 0.0018 within\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Bottom 100 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "V3001 0 0.0 ck\n",
      "V3001 1 0.0 tid\n",
      "V3001 2 0.0 comparison\n",
      "V3001 3 0.0 excluded\n",
      "V3001 4 0.0 incisions\n",
      "V3001 5 0.0 unlabored\n",
      "V3001 6 0.0 furosemide\n",
      "V3001 7 0.0 ox\n",
      "V3001 8 0.0 thrombus\n",
      "V3001 9 0.0 toxin\n",
      "V3001 10 0.0 chf\n",
      "V3001 11 0.0 anicteric\n",
      "V3001 12 0.0 gtt\n",
      "V3001 13 0.0 chronically\n",
      "V3001 14 0.0 tidal\n",
      "V3001 15 0.0 asa\n",
      "V3001 16 0.0 filling\n",
      "V3001 17 0.0 fibrillation\n",
      "V3001 18 0.0 omr\n",
      "V3001 19 0.0 know\n",
      "V3001 20 0.0 segments\n",
      "V3001 21 0.0 acetaminophen\n",
      "V3001 22 0.0 finish\n",
      "V3001 23 0.0 acutely\n",
      "V3001 24 0.0 endoscopic\n",
      "V3001 25 0.0 creat\n",
      "V3001 26 0.0 deceased\n",
      "V3001 27 0.0 ischemia\n",
      "V3001 28 0.0 injected\n",
      "V3001 29 0.0 clearance\n",
      "V3001 30 0.0 injection\n",
      "V3001 31 0.0 pan\n",
      "V3001 32 0.0 travel\n",
      "V3001 33 0.0 quit\n",
      "V3001 34 0.0 thrombi\n",
      "V3001 35 0.0 allowing\n",
      "V3001 36 0.0 rdw\n",
      "V3001 37 0.0 mch\n",
      "V3001 38 0.0 amenable\n",
      "V3001 39 0.0 mchc\n",
      "V3001 40 0.0 enzymes\n",
      "V3001 41 0.0 independent\n",
      "V3001 42 0.0 metoclopramide\n",
      "V3001 43 0.0 mic\n",
      "V3001 44 0.0 ldh\n",
      "V3001 45 0.0 bypass\n",
      "V3001 46 0.0 walk\n",
      "V3001 47 0.0 transaminases\n",
      "V3001 48 0.0 perrla\n",
      "V3001 49 0.0 ulcerated\n",
      "V3001 50 0.0 comments\n",
      "V3001 51 0.0 bibasilar\n",
      "V3001 52 0.0 diarrhea\n",
      "V3001 53 0.0 company\n",
      "V3001 54 0.0 angiography\n",
      "V3001 55 0.0 refused\n",
      "V3001 56 0.0 piperacillin\n",
      "V3001 57 0.0 trimethoprim\n",
      "V3001 58 0.0 leads\n",
      "V3001 59 0.0 encephalomalacia\n",
      "V3001 60 0.0 adverse\n",
      "V3001 61 0.0 amylase\n",
      "V3001 62 0.0 osteopenia\n",
      "V3001 63 0.0 qhs\n",
      "V3001 64 0.0 atrovent\n",
      "V3001 65 0.0 hyperkalemia\n",
      "V3001 66 0.0 sclerae\n",
      "V3001 67 0.0 jugular\n",
      "V3001 68 0.0 adjustment\n",
      "V3001 69 0.0 yo\n",
      "V3001 70 0.0 exacerbation\n",
      "V3001 71 0.0 multifocal\n",
      "V3001 72 0.0 ulcer\n",
      "V3001 73 0.0 sets\n",
      "V3001 74 0.0 bcx\n",
      "V3001 75 0.0 optimized\n",
      "V3001 76 0.0 pericarditis\n",
      "V3001 77 0.0 leaflets\n",
      "V3001 78 0.0 nebulizers\n",
      "V3001 79 0.0 eos\n",
      "V3001 80 0.0 resume\n",
      "V3001 81 0.0 basal\n",
      "V3001 82 0.0 chief\n",
      "V3001 83 0.0 driving\n",
      "V3001 84 0.0 dyspnea\n",
      "V3001 85 0.0 bruits\n",
      "V3001 86 0.0 sob\n",
      "V3001 87 0.0 code\n",
      "V3001 88 0.0 demerol\n",
      "V3001 89 0.0 pleasure\n",
      "V3001 90 0.0 warfarin\n",
      "V3001 91 0.0 pus\n",
      "V3001 92 0.0 heavily\n",
      "V3001 93 0.0 explain\n",
      "V3001 94 0.0 sulfa\n",
      "V3001 95 0.0 rehab\n",
      "V3001 96 0.0 lifting\n",
      "V3001 97 0.0 eat\n",
      "V3001 98 0.0 possibilities\n",
      "V3001 99 0.0 operatively\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amartins\\onedrive - intermountain healthcare\\python_pycharm_virt_env\\.venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Notes\n",
    "# sum([np.exp(1)** x for x in nb_classifier.coef_[0]]) # The probability of all the words equals one\n",
    "# # Taken from here: * https://stackoverflow.com/questions/61586946/how-to-calculate-feature-log-prob-in-the-naive-bayes-multinomialnb\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_feature_rank(tfidf_vectorizer, y_no, nb_classifier):\n",
    "    \n",
    "    # Get the feature names\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    # Zip together the first CPT weights with feature names\n",
    "    feat_with_weights =  sorted(zip(nb_classifier.coef_[y_no], feature_names))\n",
    "    \n",
    "    # Print words most responsible for the prediction\n",
    "    print('Top 100 \\n\\n\\n\\n')\n",
    "#     top_100_ls = []\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[-i-1]\n",
    "#         top_100_ls.append(x[1])\n",
    "        print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "\n",
    "    print('\\n\\n\\n\\n Bottom 100 \\n\\n\\n\\n')\n",
    "    for i in range(100):\n",
    "        x = feat_with_weights[i]\n",
    "        print(nb_classifier.classes_[y_no], i, round((np.exp(1) ** x[0]),4), x[1])\n",
    "    \n",
    "#     min_weight = min([i[0] for i in feat_with_weights])\n",
    "    \n",
    "    x = [i[0] for i in feat_with_weights]\n",
    "    \n",
    "    median_pred = np.median(x)\n",
    "    min_pred = min(x)\n",
    "          \n",
    "    return [i[1] for i in feat_with_weights if i[0] == min_pred] # Minimum weight words\n",
    "#     return top_100_ls\n",
    "\n",
    "# Find the least predictive words\n",
    "def least_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    low_wt_stop_ls = []\n",
    "\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        low_wt_stop_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    low_wt_stop_ls = list(set(low_wt_stop_ls))\n",
    "    return low_wt_stop_ls\n",
    "    \n",
    "\n",
    "# Find top 100 words - doesn't seem to improve the model\n",
    "def highest_pred_words(nb_classifier, tfidf_vectorizer):\n",
    "    top_100_ls = []\n",
    "    for i in range(len(nb_classifier.classes_)):\n",
    "        top_100_ls += get_feature_rank(tfidf_vectorizer, i, nb_classifier)\n",
    "\n",
    "    top_100_ls = list(set(top_100_ls))\n",
    "    return top_100_ls\n",
    "\n",
    "low_wt_stop_ls = least_pred_words(nb_classifier, tfidf_vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-summit",
   "metadata": {},
   "source": [
    "# Update stop words and tokenize again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "intense-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words += low_wt_stop_ls\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words, min_df = 3, max_df = .7, sublinear_tf=True)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-surface",
   "metadata": {},
   "source": [
    "# Create Vocab with top words and tokenize again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It reduced test accuracy back to 43% and training went from 50% to 44%\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=top_100_ls, stop_words=my_stop_words, min_df = 3, max_df = .7, sublinear_tf=True)\n",
    "\n",
    "# Transform the training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-remove",
   "metadata": {},
   "source": [
    "# Run Naive Bayes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "painted-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Naive Bayes model -----\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "nb_classifier = MultinomialNB(alpha=.7)\n",
    "\n",
    "# Fit and check accuracy\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-kenya",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "optimum-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0389       0.94      0.97      0.95       674\n",
      "       41071       0.96      0.92      0.94       552\n",
      "       V3001       1.00      1.00      1.00       453\n",
      "\n",
      "    accuracy                           0.96      1679\n",
      "   macro avg       0.97      0.96      0.96      1679\n",
      "weighted avg       0.96      0.96      0.96      1679\n",
      "\n",
      "Training\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0389       0.95      0.98      0.96      1302\n",
      "       41071       0.98      0.94      0.96      1167\n",
      "       V3001       1.00      1.00      1.00       937\n",
      "\n",
      "    accuracy                           0.97      3406\n",
      "   macro avg       0.97      0.97      0.97      3406\n",
      "weighted avg       0.97      0.97      0.97      3406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create classification report taken from here: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Test')\n",
    "class_labels = nb_classifier.classes_\n",
    "print(classification_report(y_test, pred,target_names=class_labels))\n",
    "\n",
    "print('Training')\n",
    "pred_x = nb_classifier.predict(tfidf_train)\n",
    "print(classification_report(y_train, pred_x,target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "italian-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9612864800476474"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "# \"\"\"\n",
    "# V1 NLP Model Accuracy: 0.117\n",
    "# Wow, I've got a long way to go to improve accuracy\n",
    "# V2 NLP Model Accuracy: 0.14\n",
    "# V3 NLP Model Accuracy: .40\n",
    "# \"\"\"\n",
    "\n",
    "# Confusion matrix \n",
    "# confusion_mtrx = metrics.confusion_matrix(y_test.astype(str), pred) # 1380, 1380\n",
    "# confusion_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "quantitative-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40142942227516376"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistical Model accuracy\n",
    "metrics.accuracy_score(y_test, logist_pred)\n",
    "# .39\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-wages",
   "metadata": {},
   "source": [
    "# Vectorize Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "objective-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 2)\t1\n",
      "  (3, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vocab = ['love', 'happy', 'run']\n",
    "count_vectorizer = CountVectorizer(vocabulary = vocab)\n",
    "x = count_vectorizer.fit_transform(['happy', 'run', 'run', 'run'])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-extra",
   "metadata": {},
   "source": [
    "# Predict Based on Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial-referral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0389\n"
     ]
    }
   ],
   "source": [
    "def predict_icd(text):\n",
    "    input_text_clean = clean_data(pd.Series(text))\n",
    "    tfidf_input_test = tfidf_vectorizer.transform(input_text_clean)\n",
    "    print(nb_classifier.predict(tfidf_input_test)[0]  )\n",
    "    \n",
    "# Source: https://www.mayoclinic.org/diseases-conditions/sepsis/symptoms-causes/syc-20351214?utm_source=Google&utm_medium=abstract&utm_content=Sepsis&utm_campaign=Knowledge-panel\n",
    "# 0389\n",
    "text_0389 = ['Sepsis occurs when chemicals released in the bloodstream to fight an infection trigger \\\n",
    "              inflammation throughout the body. This can cause a cascade of changes that damage multiple organ systems, \\\n",
    "              causing them to fail, sometimes even resulting in death.\\\n",
    "            Symptoms include fever, difficulty breathing, low blood pressure, fast heart rate, and mental confusion.\\\n",
    "            Treatment includes antibiotics and intravenous fluids.']\n",
    "\n",
    "\n",
    "# 41071\n",
    "# https://www.mayoclinic.org/diseases-conditions/myocardial-ischemia/symptoms-causes/syc-20375417\n",
    "\n",
    "text_41071 = \"\"\"\n",
    "Myocardial ischemia occurs when blood flow to your heart is reduced, preventing the heart muscle from receiving enough oxygen. The reduced blood flow is usually the result of a partial or complete blockage of your heart's arteries (coronary arteries).\n",
    "Myocardial ischemia, also called cardiac ischemia, reduces the heart muscle's ability to pump blood. A sudden, severe blockage of one of the heart's artery can lead to a heart attack. Myocardial ischemia might also cause serious abnormal heart rhythms.\n",
    "Treatment for myocardial ischemia involves improving blood flow to the heart muscle. Treatment may include medications, a procedure to open blocked arteries (angioplasty) or bypass surgery.\n",
    "Making heart-healthy lifestyle choices is important in treating and preventing myocardial ischemia.\n",
    "\"\"\"\n",
    "\n",
    "# V3001\n",
    "# https://www.mayoclinic.org/healthy-lifestyle/labor-and-delivery/basics/labor-and-delivery/hlv-20049465\n",
    "text_V3001 = \"\"\"\n",
    "Every woman's labor and delivery experience is unique. Still, understanding what's typical can help you know what to expect as your due date approaches.\n",
    "Labor and delivery generally follows a pattern  the cervix softening and opening; the amniotic sac rupturing; the contractions getting stronger and closer together. Sometimes, however, labor and delivery takes surprising twists and turns. You might reconsider your wishes about pain medication, or you might need an unexpected C-section.\n",
    "However your labor and delivery unfolds, remember that your health and your baby's health are what's most important. Discuss your labor and delivery preferences with your health care provider, including options for pain medication and thoughts about episiotomy and other procedures. Then look forward to welcoming your baby into the world.\n",
    "\"\"\"\n",
    "\n",
    "predict_icd(text_0389)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
